{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_LTBtfMBvW_"
   },
   "source": [
    "# Homework 5: Convolutional neural network (30 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you need to implement and train a convolutional neural network on the CIFAR-10 dataset with PyTorch.\n",
    "### What is PyTorch?\n",
    "\n",
    "PyTorch is a system for executing dynamic computational graphs over Tensor objects that behave similarly as numpy ndarray. It comes with a powerful automatic differentiation engine that removes the need for manual back-propagation. \n",
    "\n",
    "### Why?\n",
    "\n",
    "* Our code will now run on GPUs! Much faster training. When using a framework like PyTorch or TensorFlow you can harness the power of the GPU for your own custom neural network architectures without having to write CUDA code directly (which is beyond the scope of this class).\n",
    "* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants! TensorFlow and PyTorch are both excellent frameworks that will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* We want you to be exposed to the sort of deep learning code you might run into in academia or industry.\n",
    "## How can I learn PyTorch?\n",
    "\n",
    "Justin Johnson has made an excellent [tutorial](https://github.com/jcjohnson/pytorch-examples) for PyTorch. \n",
    "\n",
    "You can also find the detailed [API doc](http://pytorch.org/docs/stable/index.html) here. If you have other questions that are not addressed by the API docs, the [PyTorch forum](https://discuss.pytorch.org/) is a much better place to ask than StackOverflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T33dD1e8tii2"
   },
   "source": [
    "Install PyTorch and Skorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pJB3VQYDCUmh",
    "outputId": "43ab27ff-b2fb-4f7b-f517-f2b029b18ba2"
   },
   "outputs": [],
   "source": [
    "! pip install -q torch skorch torchvision torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "3l_Dl6qxCXmv",
    "outputId": "c0bbb1f4-081a-464e-bf46-a34c2767e83a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import skorch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uevQtU7NtZ_-"
   },
   "source": [
    "## 0. Tensor Operations (5 points)\n",
    "\n",
    "Tensor operations are important in deep learning models. In this part, you are required to get famaliar to some common tensor operations in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5DeQOItkeQCx"
   },
   "source": [
    "### 1) Tensor squeezing, unsqueezing and viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAOmBE5ODwpP"
   },
   "source": [
    "Tensor squeezing, unsqueezing and viewing are important methods to change the dimension of a Tensor, and the corresponding functions are [torch.squeeze](https://pytorch.org/docs/stable/torch.html#torch.squeeze), [torch.unsqueeze](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) and [torch.Tensor.view](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). Please read the documents of the functions, and finish the following practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hVrM80YxFSjb",
    "outputId": "933f2576-b413-4516-a3f8-5fa4fbe60b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# x is a tensor with size being (3, 2)\n",
    "x = torch.Tensor([[1, 2], \n",
    "                  [3, 4], \n",
    "                  [5, 6]])\n",
    "x.shape\n",
    "# Add two new dimensions to x by using the function torch.unsqueeze, so that the size of x becomes (3, 1, 2, 1).\n",
    "x = torch.unsqueeze(torch.unsqueeze(x,1),-1)\n",
    "print(x.shape)\n",
    "# Remove the two dimensions justed added by using the function torch.squeeze, and change the size of x back to (3, 2).\n",
    "x = torch.squeeze(x)\n",
    "print(x.shape)\n",
    "# x is now a two-dimensional tensor, or in other words a matrix. Now use the function torch.Tensor.view and change x to a one-dimensional vector with size being (6).\n",
    "x = x.view(6)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liuR-U0wea0n"
   },
   "source": [
    "### 2) Tensor concatenation and stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkbnt6v8Bo-j"
   },
   "source": [
    "Tensor concatenation and stack are operations to combine small tensors into big tensors. The corresponding functions are [torch.cat](https://pytorch.org/docs/stable/torch.html#torch.cat) and [torch.stack](https://pytorch.org/docs/stable/torch.html#torch.stack). Please read the documents of the functions, and finish the following practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "b9KqXu3Stfjh",
    "outputId": "97f17754-1e49-4a77-df8a-46a1200ea170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1., -2.],\n",
      "        [-3., -4.],\n",
      "        [-5., -6.]])\n"
     ]
    }
   ],
   "source": [
    "# x is a tensor with size being (3, 2)\n",
    "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# y is a tensor with size being (3, 2)\n",
    "y = torch.Tensor([[-1, -2], [-3, -4], [-5, -6]])\n",
    "\n",
    "# Our goal is to generate a tensor z with size as (2, 3, 2), and z[0,:,:] = x, z[1,:,:] = y.\n",
    "\n",
    "# Use torch.stack to generate such a z\n",
    "z = torch.stack((x,y))\n",
    "print(z[0,:,:])\n",
    "# Use torch.cat and torch.unsqueeze to generate such a z\n",
    "z = torch.cat((torch.unsqueeze(x,0),torch.unsqueeze(y,0)))\n",
    "print(z[1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGw4eEo-eeHm"
   },
   "source": [
    "### 3) Tensor expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAII9eJgJFK2"
   },
   "source": [
    "Tensor expansion is to expand a tensor into a larger tensor along singleton dimensions. The corresponding functions are [torch.Tensor.expand](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand) and [torch.Tensor.expand_as](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand_as). Please read the documents of the functions, and finish the following practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "sQbFte-AJzVL",
    "outputId": "0505d6ed-fcff-40b1-d373-2510a4deb373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# x is a tensor with size being (3)\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "\n",
    "# Our goal is to generate a tensor z with size (2, 3), so that z[0,:,:] = x, z[1,:,:] = x.\n",
    "\n",
    "# [TO DO]\n",
    "# Change the size of x into (1, 3) by using torch.unsqueeze.\n",
    "x = torch.unsqueeze(x,0)\n",
    "print(x.shape)\n",
    "\n",
    "# [TO DO]\n",
    "# Then expand the new tensor to the target tensor by using torch.Tensor.expand.\n",
    "z = x.expand(2,3)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rFL_Shoef3m"
   },
   "source": [
    "### 4) Tensor reduction in a given dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmEoJVw0LL9H"
   },
   "source": [
    "In deep learning, we often need to compute the mean/sum/max/min value in a given dimension of a tensor. Please read the document of [torch.mean](https://pytorch.org/docs/stable/torch.html#torch.mean), [torch.sum](https://pytorch.org/docs/stable/torch.html#torch.sum), [torch.max](https://pytorch.org/docs/stable/torch.html#torch.max), [torch.min](https://pytorch.org/docs/stable/torch.html#torch.min), [torch.topk](https://pytorch.org/docs/stable/torch.html#torch.topk), and finish the following practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "A7dlZwe4MNxo",
    "outputId": "1148ec88-6f73-4cdc-8471-40d431ca429b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1522)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "# x is a random tensor with size being (10, 50)\n",
    "x = torch.randn(10, 50)\n",
    "\n",
    "# Compute the mean value for each row of x.\n",
    "# You need to generate a tensor x_mean of size (10), and x_mean[k, :] is the mean value of the k-th row of x.\n",
    "x_mean = torch.mean(x,1)\n",
    "print(x_mean[3, ])\n",
    "\n",
    "# Compute the sum value for each row of x.\n",
    "# You need to generate a tensor x_sum of size (10).\n",
    "x_sum = torch.sum(x,1)\n",
    "print(x_sum.shape)\n",
    "\n",
    "# Compute the max value for each row of x.\n",
    "# You need to generate a tensor x_max of size (10).\n",
    "x_max, s = torch.max(x,1)\n",
    "print(x_max.shape)\n",
    "\n",
    "# Compute the min value for each row of x.\n",
    "# You need to generate a tensor x_min of size (10).\n",
    "x_min, s = torch.min(x,1)\n",
    "print(x_min.shape)\n",
    "\n",
    "# Compute the top-5 values for each row of x.\n",
    "# You need to generate a tensor x_mean of size (10, 5), and x_top[k, :] is the top-5 values of each row in x.\n",
    "x_mean_xtop, s = torch.topk(x,5,1)\n",
    "print((x_mean_xtop.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I49qjiqHB9oa"
   },
   "source": [
    "## Convolutional Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JePbG5pSt1xv"
   },
   "source": [
    "Implement a convolutional neural network for image classification on CIFAR-10 dataset.\n",
    "\n",
    "CIFAR-10 is an image dataset of 10 categories. Each image has a size of 32x32 pixels. The following code will download the dataset, and split it into `train` and `test`. For this question, we use the default validation split generated by Skorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "310efd92386a4757a767d5204b08a865",
      "8346dadd8dcd437f9d0c73a8e86d4503",
      "87cad6ba7ef84d03a7f8c0cb37ec01ec",
      "b712d5d1ba464a378c00dbb2aec6dd8c",
      "0f3b4a3b037d47cb8ba1196d7dbd3b98",
      "3f3ef2c146bf4dd38424170b3090b055",
      "adbb9a799ba44a91b927b44d0c27e6d1",
      "44a89539615b4132a01ca7f5223ca281"
     ]
    },
    "colab_type": "code",
    "id": "sQxOUQ29BuMB",
    "outputId": "fe539e24-4cd1-42ef-8bda-9ec1a0accd54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True)\n",
    "test = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True)\n",
    "train.targets = torch.LongTensor(train.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieBpiwMwi6wD"
   },
   "source": [
    "The following code visualizes some samples in the dataset. You may use it to debug your model if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "cU5HrxybupyJ",
    "outputId": "c9568768-b950-40b7-c16a-9d21a0969075"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(data, labels=None, num_sample=5):\n",
    "  n = min(len(data), num_sample)\n",
    "  for i in range(n):\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.imshow(data[i], cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if labels is not None:\n",
    "      plt.title(labels[i])\n",
    "\n",
    "train.labels = [train.classes[target] for target in train.targets]\n",
    "plot(train.data, train.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwzKmdcuCv1D"
   },
   "source": [
    "### 1) Basic CNN implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbEYo5WgjTtm"
   },
   "source": [
    "Consider a basic CNN model\n",
    "\n",
    "- It has 3 convolutional layers, followed by a linear layer.\n",
    "- Each convolutional layer has a kernel size of 3, a padding of 1.\n",
    "- ReLU activation is applied on every hidden layer.\n",
    "\n",
    "Please implement this model in the following section. The hyperparameters is then be tuned and you need to fill the results in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZKyE2GUfL-Z"
   },
   "source": [
    "#### a) Implement convolutional layers (10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4P_aYytExtq9"
   },
   "source": [
    "Implement the initialization function and the forward function of the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDmCKUD1LBFk"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(CNN, self).__init__()\n",
    "    # implement parameter definitions here\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    self.conv1 = nn.Conv2d(3,channels,3,padding=1)\n",
    "    self.conv2 = nn.Conv2d(channels,channels,3,padding=1)\n",
    "    self.conv3 = nn.Conv2d(channels,channels,3,padding=1)\n",
    "    self.fcl = nn.Linear(channels*32*32,10)\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "  def forward(self, images):\n",
    "    # implement the forward function here\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    images = F.relu(self.conv1(images))\n",
    "    images = F.relu(self.conv2(images))\n",
    "    images = F.relu(self.conv3(images))\n",
    "    images = images.view(images.size(0),-1)\n",
    "    images = self.fcl(images)\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_YaASPpgRiL"
   },
   "source": [
    "#### b) Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygMcDdpy6XWP"
   },
   "source": [
    "Train the CNN model on CIFAR-10 dataset. We can tune the number of channels, optimizer, learning rate and the number of epochs for best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JUaguxFA5xOp",
    "outputId": "e74d78b8-10c0-414a-93d4-128f8ca4b2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel was 16, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.3031\u001b[0m       \u001b[32m0.0922\u001b[0m        \u001b[35m2.3030\u001b[0m  33.2964\n",
      "      2        \u001b[36m2.3030\u001b[0m       \u001b[32m0.0923\u001b[0m        \u001b[35m2.3030\u001b[0m  32.4063\n",
      "      3        \u001b[36m2.3029\u001b[0m       \u001b[32m0.0928\u001b[0m        \u001b[35m2.3029\u001b[0m  31.2097\n",
      "      4        \u001b[36m2.3029\u001b[0m       \u001b[32m0.0930\u001b[0m        \u001b[35m2.3028\u001b[0m  32.2927\n",
      "      5        \u001b[36m2.3028\u001b[0m       \u001b[32m0.0932\u001b[0m        \u001b[35m2.3028\u001b[0m  31.1628\n",
      "      6        \u001b[36m2.3027\u001b[0m       \u001b[32m0.0935\u001b[0m        \u001b[35m2.3027\u001b[0m  31.4149\n",
      "      7        \u001b[36m2.3027\u001b[0m       \u001b[32m0.0940\u001b[0m        \u001b[35m2.3026\u001b[0m  30.7325\n",
      "      8        \u001b[36m2.3026\u001b[0m       0.0938        \u001b[35m2.3026\u001b[0m  30.8253\n",
      "      9        \u001b[36m2.3025\u001b[0m       \u001b[32m0.0942\u001b[0m        \u001b[35m2.3025\u001b[0m  32.8183\n",
      "     10        \u001b[36m2.3025\u001b[0m       0.0941        \u001b[35m2.3024\u001b[0m  32.3721\n",
      "     11        \u001b[36m2.3024\u001b[0m       \u001b[32m0.0945\u001b[0m        \u001b[35m2.3024\u001b[0m  31.9081\n",
      "     12        \u001b[36m2.3024\u001b[0m       \u001b[32m0.0952\u001b[0m        \u001b[35m2.3023\u001b[0m  31.5482\n",
      "     13        \u001b[36m2.3023\u001b[0m       \u001b[32m0.0959\u001b[0m        \u001b[35m2.3022\u001b[0m  31.3438\n",
      "     14        \u001b[36m2.3022\u001b[0m       \u001b[32m0.0967\u001b[0m        \u001b[35m2.3022\u001b[0m  32.1400\n",
      "     15        \u001b[36m2.3022\u001b[0m       \u001b[32m0.0982\u001b[0m        \u001b[35m2.3021\u001b[0m  31.0039\n",
      "     16        \u001b[36m2.3021\u001b[0m       \u001b[32m0.0985\u001b[0m        \u001b[35m2.3020\u001b[0m  31.0092\n",
      "     17        \u001b[36m2.3020\u001b[0m       \u001b[32m0.0996\u001b[0m        \u001b[35m2.3020\u001b[0m  32.0398\n",
      "     18        \u001b[36m2.3020\u001b[0m       \u001b[32m0.1011\u001b[0m        \u001b[35m2.3019\u001b[0m  32.9767\n",
      "     19        \u001b[36m2.3019\u001b[0m       \u001b[32m0.1020\u001b[0m        \u001b[35m2.3018\u001b[0m  31.9393\n",
      "     20        \u001b[36m2.3018\u001b[0m       \u001b[32m0.1039\u001b[0m        \u001b[35m2.3018\u001b[0m  31.2194\n",
      "     21        \u001b[36m2.3018\u001b[0m       \u001b[32m0.1051\u001b[0m        \u001b[35m2.3017\u001b[0m  32.5872\n",
      "     22        \u001b[36m2.3017\u001b[0m       \u001b[32m0.1059\u001b[0m        \u001b[35m2.3016\u001b[0m  31.4957\n",
      "     23        \u001b[36m2.3016\u001b[0m       \u001b[32m0.1072\u001b[0m        \u001b[35m2.3016\u001b[0m  31.6174\n",
      "     24        \u001b[36m2.3016\u001b[0m       \u001b[32m0.1090\u001b[0m        \u001b[35m2.3015\u001b[0m  32.3750\n",
      "     25        \u001b[36m2.3015\u001b[0m       \u001b[32m0.1118\u001b[0m        \u001b[35m2.3014\u001b[0m  32.3782\n",
      "The channel was 32, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.3026\u001b[0m       \u001b[32m0.1118\u001b[0m        \u001b[35m2.3025\u001b[0m  75.5154\n",
      "      2        \u001b[36m2.3023\u001b[0m       \u001b[32m0.1192\u001b[0m        \u001b[35m2.3022\u001b[0m  73.5765\n",
      "      3        \u001b[36m2.3021\u001b[0m       \u001b[32m0.1307\u001b[0m        \u001b[35m2.3019\u001b[0m  73.9044\n",
      "      4        \u001b[36m2.3018\u001b[0m       \u001b[32m0.1455\u001b[0m        \u001b[35m2.3016\u001b[0m  74.4299\n",
      "      5        \u001b[36m2.3015\u001b[0m       \u001b[32m0.1546\u001b[0m        \u001b[35m2.3014\u001b[0m  74.1025\n",
      "      6        \u001b[36m2.3013\u001b[0m       0.1537        \u001b[35m2.3011\u001b[0m  74.7158\n",
      "      7        \u001b[36m2.3010\u001b[0m       0.1471        \u001b[35m2.3008\u001b[0m  75.1688\n",
      "      8        \u001b[36m2.3008\u001b[0m       0.1398        \u001b[35m2.3006\u001b[0m  74.0391\n",
      "      9        \u001b[36m2.3005\u001b[0m       0.1341        \u001b[35m2.3004\u001b[0m  74.8319\n",
      "     10        \u001b[36m2.3003\u001b[0m       0.1254        \u001b[35m2.3001\u001b[0m  78.7981\n",
      "     11        \u001b[36m2.3001\u001b[0m       0.1191        \u001b[35m2.2999\u001b[0m  74.6853\n",
      "     12        \u001b[36m2.2998\u001b[0m       0.1144        \u001b[35m2.2996\u001b[0m  75.1045\n",
      "     13        \u001b[36m2.2996\u001b[0m       0.1083        \u001b[35m2.2994\u001b[0m  75.2092\n",
      "     14        \u001b[36m2.2994\u001b[0m       0.1044        \u001b[35m2.2992\u001b[0m  75.3185\n",
      "     15        \u001b[36m2.2992\u001b[0m       0.1027        \u001b[35m2.2990\u001b[0m  73.9641\n",
      "     16        \u001b[36m2.2990\u001b[0m       0.1009        \u001b[35m2.2988\u001b[0m  75.9277\n",
      "     17        \u001b[36m2.2988\u001b[0m       0.0994        \u001b[35m2.2985\u001b[0m  74.4793\n",
      "     18        \u001b[36m2.2985\u001b[0m       0.0991        \u001b[35m2.2983\u001b[0m  81.8071\n",
      "     19        \u001b[36m2.2983\u001b[0m       0.0994        \u001b[35m2.2981\u001b[0m  74.3654\n",
      "     20        \u001b[36m2.2981\u001b[0m       0.1005        \u001b[35m2.2979\u001b[0m  75.5451\n",
      "     21        \u001b[36m2.2979\u001b[0m       0.1000        \u001b[35m2.2977\u001b[0m  74.9100\n",
      "     22        \u001b[36m2.2977\u001b[0m       0.1022        \u001b[35m2.2975\u001b[0m  75.4648\n",
      "     23        \u001b[36m2.2975\u001b[0m       0.1026        \u001b[35m2.2973\u001b[0m  74.9593\n",
      "     24        \u001b[36m2.2973\u001b[0m       0.1048        \u001b[35m2.2971\u001b[0m  75.1578\n",
      "     25        \u001b[36m2.2971\u001b[0m       0.1064        \u001b[35m2.2968\u001b[0m  74.4299\n",
      "The channel was 64, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.3036\u001b[0m       \u001b[32m0.1017\u001b[0m        \u001b[35m2.3032\u001b[0m  198.9562\n",
      "      2        \u001b[36m2.3030\u001b[0m       \u001b[32m0.1063\u001b[0m        \u001b[35m2.3026\u001b[0m  198.6153\n",
      "      3        \u001b[36m2.3024\u001b[0m       \u001b[32m0.1189\u001b[0m        \u001b[35m2.3021\u001b[0m  216.3862\n",
      "      4        \u001b[36m2.3019\u001b[0m       \u001b[32m0.1192\u001b[0m        \u001b[35m2.3015\u001b[0m  223.2036\n",
      "      5        \u001b[36m2.3014\u001b[0m       0.1128        \u001b[35m2.3010\u001b[0m  216.7390\n",
      "      6        \u001b[36m2.3009\u001b[0m       0.1063        \u001b[35m2.3005\u001b[0m  217.7274\n",
      "      7        \u001b[36m2.3005\u001b[0m       0.1027        \u001b[35m2.3001\u001b[0m  217.4551\n",
      "      8        \u001b[36m2.3000\u001b[0m       0.1016        \u001b[35m2.2996\u001b[0m  204.9226\n",
      "      9        \u001b[36m2.2996\u001b[0m       0.1003        \u001b[35m2.2992\u001b[0m  188.9512\n",
      "     10        \u001b[36m2.2991\u001b[0m       0.1001        \u001b[35m2.2987\u001b[0m  187.3891\n",
      "     11        \u001b[36m2.2987\u001b[0m       0.1002        \u001b[35m2.2983\u001b[0m  190.4109\n",
      "     12        \u001b[36m2.2982\u001b[0m       0.0998        \u001b[35m2.2978\u001b[0m  189.4197\n",
      "     13        \u001b[36m2.2978\u001b[0m       0.0997        \u001b[35m2.2974\u001b[0m  188.3463\n",
      "     14        \u001b[36m2.2974\u001b[0m       0.0996        \u001b[35m2.2969\u001b[0m  187.0955\n",
      "     15        \u001b[36m2.2969\u001b[0m       0.0995        \u001b[35m2.2965\u001b[0m  189.2065\n",
      "     16        \u001b[36m2.2965\u001b[0m       0.0994        \u001b[35m2.2960\u001b[0m  191.9360\n",
      "     17        \u001b[36m2.2961\u001b[0m       0.0997        \u001b[35m2.2956\u001b[0m  189.1270\n",
      "     18        \u001b[36m2.2956\u001b[0m       0.0997        \u001b[35m2.2951\u001b[0m  191.8527\n",
      "     19        \u001b[36m2.2952\u001b[0m       0.0998        \u001b[35m2.2946\u001b[0m  194.3153\n",
      "     20        \u001b[36m2.2947\u001b[0m       0.1001        \u001b[35m2.2941\u001b[0m  195.2716\n",
      "     21        \u001b[36m2.2942\u001b[0m       0.1001        \u001b[35m2.2937\u001b[0m  195.4924\n",
      "     22        \u001b[36m2.2937\u001b[0m       0.1000        \u001b[35m2.2932\u001b[0m  193.3946\n",
      "     23        \u001b[36m2.2933\u001b[0m       0.1009        \u001b[35m2.2927\u001b[0m  196.2878\n",
      "     24        \u001b[36m2.2928\u001b[0m       0.1013        \u001b[35m2.2922\u001b[0m  195.4867\n",
      "     25        \u001b[36m2.2923\u001b[0m       0.1014        \u001b[35m2.2916\u001b[0m  190.2633\n",
      "The channel was 16, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2091\u001b[0m       \u001b[32m0.2735\u001b[0m        \u001b[35m2.0809\u001b[0m  40.5973\n",
      "      2        \u001b[36m2.0070\u001b[0m       \u001b[32m0.3232\u001b[0m        \u001b[35m1.9368\u001b[0m  29.1095\n",
      "      3        \u001b[36m1.9032\u001b[0m       \u001b[32m0.3541\u001b[0m        \u001b[35m1.8627\u001b[0m  29.8156\n",
      "      4        \u001b[36m1.8488\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m1.8235\u001b[0m  30.3466\n",
      "      5        \u001b[36m1.8154\u001b[0m       \u001b[32m0.3802\u001b[0m        \u001b[35m1.7928\u001b[0m  30.2068\n",
      "      6        \u001b[36m1.7868\u001b[0m       \u001b[32m0.3920\u001b[0m        \u001b[35m1.7661\u001b[0m  41.0151\n",
      "      7        \u001b[36m1.7605\u001b[0m       \u001b[32m0.4017\u001b[0m        \u001b[35m1.7412\u001b[0m  31.3739\n",
      "      8        \u001b[36m1.7365\u001b[0m       \u001b[32m0.4086\u001b[0m        \u001b[35m1.7184\u001b[0m  31.1535\n",
      "      9        \u001b[36m1.7132\u001b[0m       \u001b[32m0.4165\u001b[0m        \u001b[35m1.6963\u001b[0m  31.2500\n",
      "     10        \u001b[36m1.6912\u001b[0m       \u001b[32m0.4213\u001b[0m        \u001b[35m1.6774\u001b[0m  42.8885\n",
      "     11        \u001b[36m1.6731\u001b[0m       \u001b[32m0.4237\u001b[0m        \u001b[35m1.6618\u001b[0m  31.5856\n",
      "     12        \u001b[36m1.6574\u001b[0m       \u001b[32m0.4282\u001b[0m        \u001b[35m1.6478\u001b[0m  31.1994\n",
      "     13        \u001b[36m1.6430\u001b[0m       \u001b[32m0.4318\u001b[0m        \u001b[35m1.6349\u001b[0m  30.9401\n",
      "     14        \u001b[36m1.6297\u001b[0m       \u001b[32m0.4361\u001b[0m        \u001b[35m1.6229\u001b[0m  32.1891\n",
      "     15        \u001b[36m1.6174\u001b[0m       \u001b[32m0.4398\u001b[0m        \u001b[35m1.6118\u001b[0m  31.5050\n",
      "     16        \u001b[36m1.6059\u001b[0m       \u001b[32m0.4441\u001b[0m        \u001b[35m1.6014\u001b[0m  30.8917\n",
      "     17        \u001b[36m1.5951\u001b[0m       \u001b[32m0.4468\u001b[0m        \u001b[35m1.5917\u001b[0m  31.0846\n",
      "     18        \u001b[36m1.5849\u001b[0m       \u001b[32m0.4492\u001b[0m        \u001b[35m1.5825\u001b[0m  77.5715\n",
      "     19        \u001b[36m1.5752\u001b[0m       \u001b[32m0.4510\u001b[0m        \u001b[35m1.5737\u001b[0m  30.6983\n",
      "     20        \u001b[36m1.5659\u001b[0m       \u001b[32m0.4541\u001b[0m        \u001b[35m1.5653\u001b[0m  31.0534\n",
      "     21        \u001b[36m1.5569\u001b[0m       \u001b[32m0.4564\u001b[0m        \u001b[35m1.5572\u001b[0m  31.2100\n",
      "     22        \u001b[36m1.5483\u001b[0m       \u001b[32m0.4584\u001b[0m        \u001b[35m1.5494\u001b[0m  31.0877\n",
      "     23        \u001b[36m1.5399\u001b[0m       \u001b[32m0.4624\u001b[0m        \u001b[35m1.5419\u001b[0m  31.1569\n",
      "     24        \u001b[36m1.5318\u001b[0m       \u001b[32m0.4653\u001b[0m        \u001b[35m1.5347\u001b[0m  31.5902\n",
      "     25        \u001b[36m1.5240\u001b[0m       \u001b[32m0.4679\u001b[0m        \u001b[35m1.5277\u001b[0m  31.0664\n",
      "The channel was 32, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.1149\u001b[0m       \u001b[32m0.3102\u001b[0m        \u001b[35m1.9411\u001b[0m  74.5811\n",
      "      2        \u001b[36m1.8789\u001b[0m       \u001b[32m0.3659\u001b[0m        \u001b[35m1.8154\u001b[0m  75.3951\n",
      "      3        \u001b[36m1.7784\u001b[0m       \u001b[32m0.3966\u001b[0m        \u001b[35m1.7454\u001b[0m  75.3582\n",
      "      4        \u001b[36m1.7204\u001b[0m       \u001b[32m0.4144\u001b[0m        \u001b[35m1.6974\u001b[0m  76.2177\n",
      "      5        \u001b[36m1.6808\u001b[0m       \u001b[32m0.4245\u001b[0m        \u001b[35m1.6626\u001b[0m  75.5505\n",
      "      6        \u001b[36m1.6494\u001b[0m       \u001b[32m0.4339\u001b[0m        \u001b[35m1.6335\u001b[0m  74.8786\n",
      "      7        \u001b[36m1.6202\u001b[0m       \u001b[32m0.4427\u001b[0m        \u001b[35m1.6066\u001b[0m  75.0219\n",
      "      8        \u001b[36m1.5946\u001b[0m       \u001b[32m0.4501\u001b[0m        \u001b[35m1.5847\u001b[0m  75.0177\n",
      "      9        \u001b[36m1.5721\u001b[0m       \u001b[32m0.4590\u001b[0m        \u001b[35m1.5651\u001b[0m  74.8159\n",
      "     10        \u001b[36m1.5513\u001b[0m       \u001b[32m0.4648\u001b[0m        \u001b[35m1.5471\u001b[0m  75.3309\n",
      "     11        \u001b[36m1.5320\u001b[0m       \u001b[32m0.4698\u001b[0m        \u001b[35m1.5309\u001b[0m  106.3320\n",
      "     12        \u001b[36m1.5143\u001b[0m       \u001b[32m0.4753\u001b[0m        \u001b[35m1.5164\u001b[0m  101.5381\n",
      "     13        \u001b[36m1.4982\u001b[0m       \u001b[32m0.4784\u001b[0m        \u001b[35m1.5034\u001b[0m  110.2510\n",
      "     14        \u001b[36m1.4836\u001b[0m       \u001b[32m0.4833\u001b[0m        \u001b[35m1.4916\u001b[0m  74.4855\n",
      "     15        \u001b[36m1.4703\u001b[0m       \u001b[32m0.4884\u001b[0m        \u001b[35m1.4810\u001b[0m  74.0732\n",
      "     16        \u001b[36m1.4580\u001b[0m       \u001b[32m0.4913\u001b[0m        \u001b[35m1.4713\u001b[0m  75.0069\n",
      "     17        \u001b[36m1.4466\u001b[0m       \u001b[32m0.4930\u001b[0m        \u001b[35m1.4623\u001b[0m  74.2623\n",
      "     18        \u001b[36m1.4360\u001b[0m       \u001b[32m0.4959\u001b[0m        \u001b[35m1.4540\u001b[0m  74.7864\n",
      "     19        \u001b[36m1.4259\u001b[0m       \u001b[32m0.4992\u001b[0m        \u001b[35m1.4461\u001b[0m  74.6959\n",
      "     20        \u001b[36m1.4163\u001b[0m       \u001b[32m0.5011\u001b[0m        \u001b[35m1.4385\u001b[0m  72.3184\n",
      "     21        \u001b[36m1.4070\u001b[0m       \u001b[32m0.5018\u001b[0m        \u001b[35m1.4311\u001b[0m  69.3383\n",
      "     22        \u001b[36m1.3980\u001b[0m       \u001b[32m0.5041\u001b[0m        \u001b[35m1.4240\u001b[0m  71.3612\n",
      "     23        \u001b[36m1.3893\u001b[0m       \u001b[32m0.5057\u001b[0m        \u001b[35m1.4170\u001b[0m  75.2446\n",
      "     24        \u001b[36m1.3807\u001b[0m       \u001b[32m0.5084\u001b[0m        \u001b[35m1.4101\u001b[0m  75.8924\n",
      "     25        \u001b[36m1.3722\u001b[0m       \u001b[32m0.5103\u001b[0m        \u001b[35m1.4032\u001b[0m  75.8757\n",
      "The channel was 64, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.0151\u001b[0m       \u001b[32m0.3576\u001b[0m        \u001b[35m1.8291\u001b[0m  202.1270\n",
      "      2        \u001b[36m1.7419\u001b[0m       \u001b[32m0.4183\u001b[0m        \u001b[35m1.6770\u001b[0m  198.7369\n",
      "      3        \u001b[36m1.6265\u001b[0m       \u001b[32m0.4446\u001b[0m        \u001b[35m1.5937\u001b[0m  201.3592\n",
      "      4        \u001b[36m1.5591\u001b[0m       \u001b[32m0.4619\u001b[0m        \u001b[35m1.5433\u001b[0m  202.4845\n",
      "      5        \u001b[36m1.5155\u001b[0m       \u001b[32m0.4742\u001b[0m        \u001b[35m1.5105\u001b[0m  201.6903\n",
      "      6        \u001b[36m1.4847\u001b[0m       \u001b[32m0.4827\u001b[0m        \u001b[35m1.4870\u001b[0m  203.2900\n",
      "      7        \u001b[36m1.4607\u001b[0m       \u001b[32m0.4893\u001b[0m        \u001b[35m1.4681\u001b[0m  203.0224\n",
      "      8        \u001b[36m1.4403\u001b[0m       \u001b[32m0.4940\u001b[0m        \u001b[35m1.4518\u001b[0m  200.8325\n",
      "      9        \u001b[36m1.4219\u001b[0m       \u001b[32m0.4975\u001b[0m        \u001b[35m1.4366\u001b[0m  202.5638\n",
      "     10        \u001b[36m1.4045\u001b[0m       \u001b[32m0.5019\u001b[0m        \u001b[35m1.4221\u001b[0m  203.0319\n",
      "     11        \u001b[36m1.3877\u001b[0m       \u001b[32m0.5031\u001b[0m        \u001b[35m1.4080\u001b[0m  201.4224\n",
      "     12        \u001b[36m1.3717\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m1.3944\u001b[0m  203.0768\n",
      "     13        \u001b[36m1.3564\u001b[0m       \u001b[32m0.5113\u001b[0m        \u001b[35m1.3812\u001b[0m  201.1022\n",
      "     14        \u001b[36m1.3416\u001b[0m       \u001b[32m0.5164\u001b[0m        \u001b[35m1.3682\u001b[0m  201.2386\n",
      "     15        \u001b[36m1.3271\u001b[0m       \u001b[32m0.5193\u001b[0m        \u001b[35m1.3552\u001b[0m  202.8182\n",
      "     16        \u001b[36m1.3126\u001b[0m       \u001b[32m0.5223\u001b[0m        \u001b[35m1.3426\u001b[0m  202.0798\n",
      "     17        \u001b[36m1.2989\u001b[0m       \u001b[32m0.5263\u001b[0m        \u001b[35m1.3308\u001b[0m  203.6543\n",
      "     18        \u001b[36m1.2858\u001b[0m       \u001b[32m0.5293\u001b[0m        \u001b[35m1.3196\u001b[0m  204.5527\n",
      "     19        \u001b[36m1.2733\u001b[0m       \u001b[32m0.5334\u001b[0m        \u001b[35m1.3090\u001b[0m  202.7144\n",
      "     20        \u001b[36m1.2615\u001b[0m       \u001b[32m0.5381\u001b[0m        \u001b[35m1.2991\u001b[0m  202.4044\n",
      "     21        \u001b[36m1.2502\u001b[0m       \u001b[32m0.5427\u001b[0m        \u001b[35m1.2899\u001b[0m  202.2083\n",
      "     22        \u001b[36m1.2396\u001b[0m       \u001b[32m0.5456\u001b[0m        \u001b[35m1.2816\u001b[0m  204.1165\n",
      "     23        \u001b[36m1.2296\u001b[0m       \u001b[32m0.5494\u001b[0m        \u001b[35m1.2738\u001b[0m  204.8423\n",
      "     24        \u001b[36m1.2201\u001b[0m       \u001b[32m0.5541\u001b[0m        \u001b[35m1.2667\u001b[0m  204.6857\n",
      "     25        \u001b[36m1.2112\u001b[0m       \u001b[32m0.5566\u001b[0m        \u001b[35m1.2601\u001b[0m  198.3856\n",
      "The channel was 16, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.3032\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3029\u001b[0m  28.7028\n",
      "      2        \u001b[36m2.3028\u001b[0m       0.1000        \u001b[35m2.3026\u001b[0m  28.3354\n",
      "      3        \u001b[36m2.3025\u001b[0m       0.1000        \u001b[35m2.3024\u001b[0m  28.4123\n",
      "      4        \u001b[36m2.3023\u001b[0m       0.1000        \u001b[35m2.3021\u001b[0m  27.5514\n",
      "      5        \u001b[36m2.3021\u001b[0m       0.0996        \u001b[35m2.3019\u001b[0m  28.1030\n",
      "      6        \u001b[36m2.3019\u001b[0m       \u001b[32m0.1098\u001b[0m        \u001b[35m2.3017\u001b[0m  29.9903\n",
      "      7        \u001b[36m2.3017\u001b[0m       \u001b[32m0.1358\u001b[0m        \u001b[35m2.3015\u001b[0m  28.3431\n",
      "      8        \u001b[36m2.3014\u001b[0m       0.1344        \u001b[35m2.3012\u001b[0m  28.8486\n",
      "      9        \u001b[36m2.3012\u001b[0m       0.1194        \u001b[35m2.3010\u001b[0m  28.3444\n",
      "     10        \u001b[36m2.3009\u001b[0m       0.1104        \u001b[35m2.3007\u001b[0m  29.0628\n",
      "     11        \u001b[36m2.3006\u001b[0m       0.1101        \u001b[35m2.3004\u001b[0m  29.2648\n",
      "     12        \u001b[36m2.3003\u001b[0m       0.1119        \u001b[35m2.3000\u001b[0m  28.6420\n",
      "     13        \u001b[36m2.2999\u001b[0m       0.1138        \u001b[35m2.2996\u001b[0m  29.5950\n",
      "     14        \u001b[36m2.2994\u001b[0m       0.1148        \u001b[35m2.2991\u001b[0m  29.9916\n",
      "     15        \u001b[36m2.2990\u001b[0m       0.1152        \u001b[35m2.2985\u001b[0m  31.6355\n",
      "     16        \u001b[36m2.2984\u001b[0m       0.1147        \u001b[35m2.2979\u001b[0m  29.3639\n",
      "     17        \u001b[36m2.2978\u001b[0m       0.1155        \u001b[35m2.2973\u001b[0m  29.2405\n",
      "     18        \u001b[36m2.2971\u001b[0m       0.1178        \u001b[35m2.2965\u001b[0m  29.2563\n",
      "     19        \u001b[36m2.2963\u001b[0m       0.1187        \u001b[35m2.2957\u001b[0m  28.8609\n",
      "     20        \u001b[36m2.2955\u001b[0m       0.1214        \u001b[35m2.2948\u001b[0m  28.9748\n",
      "     21        \u001b[36m2.2945\u001b[0m       0.1237        \u001b[35m2.2937\u001b[0m  29.7247\n",
      "     22        \u001b[36m2.2934\u001b[0m       0.1259        \u001b[35m2.2925\u001b[0m  29.3646\n",
      "     23        \u001b[36m2.2921\u001b[0m       0.1292        \u001b[35m2.2911\u001b[0m  29.2549\n",
      "     24        \u001b[36m2.2907\u001b[0m       0.1312        \u001b[35m2.2895\u001b[0m  28.1076\n",
      "     25        \u001b[36m2.2890\u001b[0m       0.1330        \u001b[35m2.2876\u001b[0m  29.5127\n",
      "The channel was 32, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.3019\u001b[0m       \u001b[32m0.1010\u001b[0m        \u001b[35m2.3004\u001b[0m  71.7964\n",
      "      2        \u001b[36m2.2990\u001b[0m       0.0957        \u001b[35m2.2975\u001b[0m  71.3975\n",
      "      3        \u001b[36m2.2961\u001b[0m       \u001b[32m0.1035\u001b[0m        \u001b[35m2.2944\u001b[0m  72.1388\n",
      "      4        \u001b[36m2.2929\u001b[0m       \u001b[32m0.1090\u001b[0m        \u001b[35m2.2909\u001b[0m  71.7891\n",
      "      5        \u001b[36m2.2892\u001b[0m       \u001b[32m0.1129\u001b[0m        \u001b[35m2.2868\u001b[0m  72.7883\n",
      "      6        \u001b[36m2.2847\u001b[0m       \u001b[32m0.1206\u001b[0m        \u001b[35m2.2818\u001b[0m  71.2684\n",
      "      7        \u001b[36m2.2794\u001b[0m       \u001b[32m0.1338\u001b[0m        \u001b[35m2.2758\u001b[0m  70.9856\n",
      "      8        \u001b[36m2.2729\u001b[0m       \u001b[32m0.1507\u001b[0m        \u001b[35m2.2685\u001b[0m  72.8750\n",
      "      9        \u001b[36m2.2650\u001b[0m       \u001b[32m0.1693\u001b[0m        \u001b[35m2.2595\u001b[0m  71.1035\n",
      "     10        \u001b[36m2.2553\u001b[0m       \u001b[32m0.1898\u001b[0m        \u001b[35m2.2485\u001b[0m  73.5009\n",
      "     11        \u001b[36m2.2432\u001b[0m       \u001b[32m0.2095\u001b[0m        \u001b[35m2.2347\u001b[0m  72.6865\n",
      "     12        \u001b[36m2.2283\u001b[0m       \u001b[32m0.2266\u001b[0m        \u001b[35m2.2178\u001b[0m  71.6683\n",
      "     13        \u001b[36m2.2100\u001b[0m       \u001b[32m0.2424\u001b[0m        \u001b[35m2.1972\u001b[0m  71.6845\n",
      "     14        \u001b[36m2.1879\u001b[0m       \u001b[32m0.2544\u001b[0m        \u001b[35m2.1726\u001b[0m  72.0716\n",
      "     15        \u001b[36m2.1620\u001b[0m       \u001b[32m0.2632\u001b[0m        \u001b[35m2.1445\u001b[0m  71.5759\n",
      "     16        \u001b[36m2.1333\u001b[0m       \u001b[32m0.2672\u001b[0m        \u001b[35m2.1144\u001b[0m  72.5669\n",
      "     17        \u001b[36m2.1039\u001b[0m       \u001b[32m0.2737\u001b[0m        \u001b[35m2.0849\u001b[0m  71.9720\n",
      "     18        \u001b[36m2.0761\u001b[0m       \u001b[32m0.2800\u001b[0m        \u001b[35m2.0577\u001b[0m  71.5721\n",
      "     19        \u001b[36m2.0511\u001b[0m       \u001b[32m0.2833\u001b[0m        \u001b[35m2.0338\u001b[0m  71.3198\n",
      "     20        \u001b[36m2.0293\u001b[0m       \u001b[32m0.2873\u001b[0m        \u001b[35m2.0132\u001b[0m  72.4818\n",
      "     21        \u001b[36m2.0106\u001b[0m       \u001b[32m0.2932\u001b[0m        \u001b[35m1.9956\u001b[0m  73.3503\n",
      "     22        \u001b[36m1.9946\u001b[0m       \u001b[32m0.2983\u001b[0m        \u001b[35m1.9805\u001b[0m  71.5927\n",
      "     23        \u001b[36m1.9807\u001b[0m       \u001b[32m0.3028\u001b[0m        \u001b[35m1.9673\u001b[0m  71.5969\n",
      "     24        \u001b[36m1.9683\u001b[0m       \u001b[32m0.3082\u001b[0m        \u001b[35m1.9554\u001b[0m  71.0115\n",
      "     25        \u001b[36m1.9570\u001b[0m       \u001b[32m0.3136\u001b[0m        \u001b[35m1.9445\u001b[0m  71.7138\n",
      "The channel was 64, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.3009\u001b[0m       \u001b[32m0.1120\u001b[0m        \u001b[35m2.2982\u001b[0m  195.1902\n",
      "      2        \u001b[36m2.2964\u001b[0m       0.1066        \u001b[35m2.2936\u001b[0m  194.0137\n",
      "      3        \u001b[36m2.2916\u001b[0m       0.1109        \u001b[35m2.2885\u001b[0m  194.2230\n",
      "      4        \u001b[36m2.2862\u001b[0m       \u001b[32m0.1200\u001b[0m        \u001b[35m2.2823\u001b[0m  195.4474\n",
      "      5        \u001b[36m2.2794\u001b[0m       \u001b[32m0.1364\u001b[0m        \u001b[35m2.2745\u001b[0m  195.2063\n",
      "      6        \u001b[36m2.2707\u001b[0m       \u001b[32m0.1554\u001b[0m        \u001b[35m2.2645\u001b[0m  193.1715\n",
      "      7        \u001b[36m2.2595\u001b[0m       \u001b[32m0.1787\u001b[0m        \u001b[35m2.2514\u001b[0m  194.5282\n",
      "      8        \u001b[36m2.2449\u001b[0m       \u001b[32m0.1982\u001b[0m        \u001b[35m2.2345\u001b[0m  195.8728\n",
      "      9        \u001b[36m2.2262\u001b[0m       \u001b[32m0.2093\u001b[0m        \u001b[35m2.2133\u001b[0m  194.8654\n",
      "     10        \u001b[36m2.2034\u001b[0m       \u001b[32m0.2224\u001b[0m        \u001b[35m2.1881\u001b[0m  194.6705\n",
      "     11        \u001b[36m2.1772\u001b[0m       \u001b[32m0.2323\u001b[0m        \u001b[35m2.1603\u001b[0m  195.2831\n",
      "     12        \u001b[36m2.1495\u001b[0m       \u001b[32m0.2421\u001b[0m        \u001b[35m2.1323\u001b[0m  196.9269\n",
      "     13        \u001b[36m2.1227\u001b[0m       \u001b[32m0.2524\u001b[0m        \u001b[35m2.1065\u001b[0m  193.8297\n",
      "     14        \u001b[36m2.0984\u001b[0m       \u001b[32m0.2648\u001b[0m        \u001b[35m2.0832\u001b[0m  194.5961\n",
      "     15        \u001b[36m2.0761\u001b[0m       \u001b[32m0.2734\u001b[0m        \u001b[35m2.0616\u001b[0m  194.1725\n",
      "     16        \u001b[36m2.0549\u001b[0m       \u001b[32m0.2848\u001b[0m        \u001b[35m2.0406\u001b[0m  194.5781\n",
      "     17        \u001b[36m2.0340\u001b[0m       \u001b[32m0.2949\u001b[0m        \u001b[35m2.0197\u001b[0m  196.1359\n",
      "     18        \u001b[36m2.0132\u001b[0m       \u001b[32m0.3010\u001b[0m        \u001b[35m1.9989\u001b[0m  197.9209\n",
      "     19        \u001b[36m1.9929\u001b[0m       \u001b[32m0.3081\u001b[0m        \u001b[35m1.9790\u001b[0m  195.3134\n",
      "     20        \u001b[36m1.9740\u001b[0m       \u001b[32m0.3152\u001b[0m        \u001b[35m1.9606\u001b[0m  195.0304\n",
      "     21        \u001b[36m1.9568\u001b[0m       \u001b[32m0.3224\u001b[0m        \u001b[35m1.9441\u001b[0m  197.6767\n",
      "     22        \u001b[36m1.9417\u001b[0m       \u001b[32m0.3277\u001b[0m        \u001b[35m1.9298\u001b[0m  198.4896\n",
      "     23        \u001b[36m1.9287\u001b[0m       \u001b[32m0.3320\u001b[0m        \u001b[35m1.9175\u001b[0m  196.9817\n",
      "     24        \u001b[36m1.9176\u001b[0m       \u001b[32m0.3345\u001b[0m        \u001b[35m1.9069\u001b[0m  196.7081\n",
      "     25        \u001b[36m1.9080\u001b[0m       \u001b[32m0.3358\u001b[0m        \u001b[35m1.8977\u001b[0m  193.1102\n",
      "The channel was 16, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m1.9091\u001b[0m       \u001b[32m0.4104\u001b[0m        \u001b[35m1.6901\u001b[0m  30.7223\n",
      "      2        \u001b[36m1.6127\u001b[0m       \u001b[32m0.4607\u001b[0m        \u001b[35m1.5194\u001b[0m  30.9500\n",
      "      3        \u001b[36m1.5025\u001b[0m       \u001b[32m0.4793\u001b[0m        \u001b[35m1.4623\u001b[0m  30.9233\n",
      "      4        \u001b[36m1.4517\u001b[0m       \u001b[32m0.4902\u001b[0m        \u001b[35m1.4305\u001b[0m  30.2721\n",
      "      5        \u001b[36m1.4129\u001b[0m       \u001b[32m0.5029\u001b[0m        \u001b[35m1.3984\u001b[0m  31.8046\n",
      "      6        \u001b[36m1.3701\u001b[0m       \u001b[32m0.5123\u001b[0m        \u001b[35m1.3735\u001b[0m  31.1818\n",
      "      7        \u001b[36m1.3288\u001b[0m       \u001b[32m0.5216\u001b[0m        \u001b[35m1.3455\u001b[0m  31.5237\n",
      "      8        \u001b[36m1.2937\u001b[0m       \u001b[32m0.5321\u001b[0m        \u001b[35m1.3172\u001b[0m  31.0971\n",
      "      9        \u001b[36m1.2590\u001b[0m       \u001b[32m0.5437\u001b[0m        \u001b[35m1.2906\u001b[0m  30.9779\n",
      "     10        \u001b[36m1.2283\u001b[0m       \u001b[32m0.5503\u001b[0m        \u001b[35m1.2708\u001b[0m  30.2025\n",
      "     11        \u001b[36m1.2016\u001b[0m       \u001b[32m0.5568\u001b[0m        \u001b[35m1.2541\u001b[0m  31.1930\n",
      "     12        \u001b[36m1.1771\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m1.2402\u001b[0m  31.1481\n",
      "     13        \u001b[36m1.1543\u001b[0m       \u001b[32m0.5667\u001b[0m        \u001b[35m1.2282\u001b[0m  31.0480\n",
      "     14        \u001b[36m1.1332\u001b[0m       \u001b[32m0.5718\u001b[0m        \u001b[35m1.2180\u001b[0m  30.6424\n",
      "     15        \u001b[36m1.1136\u001b[0m       \u001b[32m0.5761\u001b[0m        \u001b[35m1.2095\u001b[0m  31.3306\n",
      "     16        \u001b[36m1.0954\u001b[0m       \u001b[32m0.5794\u001b[0m        \u001b[35m1.2020\u001b[0m  31.3529\n",
      "     17        \u001b[36m1.0785\u001b[0m       \u001b[32m0.5811\u001b[0m        \u001b[35m1.1952\u001b[0m  31.1834\n",
      "     18        \u001b[36m1.0627\u001b[0m       \u001b[32m0.5817\u001b[0m        \u001b[35m1.1891\u001b[0m  31.1058\n",
      "     19        \u001b[36m1.0478\u001b[0m       \u001b[32m0.5851\u001b[0m        \u001b[35m1.1836\u001b[0m  31.0362\n",
      "     20        \u001b[36m1.0336\u001b[0m       \u001b[32m0.5861\u001b[0m        \u001b[35m1.1784\u001b[0m  30.9513\n",
      "     21        \u001b[36m1.0201\u001b[0m       \u001b[32m0.5883\u001b[0m        \u001b[35m1.1740\u001b[0m  31.1171\n",
      "     22        \u001b[36m1.0072\u001b[0m       \u001b[32m0.5902\u001b[0m        \u001b[35m1.1700\u001b[0m  31.0392\n",
      "     23        \u001b[36m0.9948\u001b[0m       \u001b[32m0.5936\u001b[0m        \u001b[35m1.1660\u001b[0m  30.5617\n",
      "     24        \u001b[36m0.9829\u001b[0m       \u001b[32m0.5959\u001b[0m        \u001b[35m1.1625\u001b[0m  30.8305\n",
      "     25        \u001b[36m0.9713\u001b[0m       \u001b[32m0.5972\u001b[0m        \u001b[35m1.1596\u001b[0m  31.4569\n",
      "The channel was 32, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m1.7448\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m1.5068\u001b[0m  75.5064\n",
      "      2        \u001b[36m1.4580\u001b[0m       \u001b[32m0.5062\u001b[0m        \u001b[35m1.3951\u001b[0m  75.1589\n",
      "      3        \u001b[36m1.3332\u001b[0m       \u001b[32m0.5375\u001b[0m        \u001b[35m1.3080\u001b[0m  75.4120\n",
      "      4        \u001b[36m1.2465\u001b[0m       \u001b[32m0.5582\u001b[0m        \u001b[35m1.2512\u001b[0m  75.9160\n",
      "      5        \u001b[36m1.1877\u001b[0m       \u001b[32m0.5734\u001b[0m        \u001b[35m1.2123\u001b[0m  75.0868\n",
      "      6        \u001b[36m1.1410\u001b[0m       \u001b[32m0.5847\u001b[0m        \u001b[35m1.1852\u001b[0m  74.9629\n",
      "      7        \u001b[36m1.1002\u001b[0m       \u001b[32m0.5949\u001b[0m        \u001b[35m1.1653\u001b[0m  75.5087\n",
      "      8        \u001b[36m1.0633\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1492\u001b[0m  75.9712\n",
      "      9        \u001b[36m1.0295\u001b[0m       \u001b[32m0.6058\u001b[0m        \u001b[35m1.1342\u001b[0m  76.0611\n",
      "     10        \u001b[36m0.9980\u001b[0m       \u001b[32m0.6107\u001b[0m        \u001b[35m1.1192\u001b[0m  75.7848\n",
      "     11        \u001b[36m0.9679\u001b[0m       \u001b[32m0.6156\u001b[0m        \u001b[35m1.1054\u001b[0m  75.7735\n",
      "     12        \u001b[36m0.9389\u001b[0m       \u001b[32m0.6199\u001b[0m        \u001b[35m1.0942\u001b[0m  76.3694\n",
      "     13        \u001b[36m0.9105\u001b[0m       \u001b[32m0.6219\u001b[0m        \u001b[35m1.0854\u001b[0m  76.6931\n",
      "     14        \u001b[36m0.8830\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m1.0779\u001b[0m  75.8649\n",
      "     15        \u001b[36m0.8561\u001b[0m       \u001b[32m0.6296\u001b[0m        \u001b[35m1.0724\u001b[0m  76.3687\n",
      "     16        \u001b[36m0.8300\u001b[0m       \u001b[32m0.6347\u001b[0m        \u001b[35m1.0692\u001b[0m  76.4422\n",
      "     17        \u001b[36m0.8044\u001b[0m       \u001b[32m0.6380\u001b[0m        \u001b[35m1.0671\u001b[0m  83.2052\n",
      "     18        \u001b[36m0.7794\u001b[0m       \u001b[32m0.6387\u001b[0m        1.0675  75.9804\n",
      "     19        \u001b[36m0.7552\u001b[0m       \u001b[32m0.6392\u001b[0m        1.0690  75.9325\n",
      "     20        \u001b[36m0.7316\u001b[0m       \u001b[32m0.6395\u001b[0m        1.0721  76.2727\n",
      "     21        \u001b[36m0.7087\u001b[0m       0.6395        1.0767  76.2571\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 64, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m1.6846\u001b[0m       \u001b[32m0.4873\u001b[0m        \u001b[35m1.4493\u001b[0m  199.5793\n",
      "      2        \u001b[36m1.3539\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m1.2738\u001b[0m  199.9522\n",
      "      3        \u001b[36m1.2091\u001b[0m       \u001b[32m0.5765\u001b[0m        \u001b[35m1.2135\u001b[0m  200.8681\n",
      "      4        \u001b[36m1.1118\u001b[0m       \u001b[32m0.5935\u001b[0m        \u001b[35m1.1575\u001b[0m  200.6454\n",
      "      5        \u001b[36m1.0238\u001b[0m       \u001b[32m0.6135\u001b[0m        \u001b[35m1.1113\u001b[0m  201.8104\n",
      "      6        \u001b[36m0.9444\u001b[0m       \u001b[32m0.6264\u001b[0m        \u001b[35m1.0786\u001b[0m  201.4504\n",
      "      7        \u001b[36m0.8754\u001b[0m       \u001b[32m0.6313\u001b[0m        \u001b[35m1.0595\u001b[0m  203.6201\n",
      "      8        \u001b[36m0.8145\u001b[0m       \u001b[32m0.6402\u001b[0m        \u001b[35m1.0516\u001b[0m  202.8307\n",
      "      9        \u001b[36m0.7593\u001b[0m       \u001b[32m0.6422\u001b[0m        1.0526  200.6320\n",
      "     10        \u001b[36m0.7077\u001b[0m       \u001b[32m0.6450\u001b[0m        1.0609  203.2361\n",
      "     11        \u001b[36m0.6587\u001b[0m       0.6443        1.0765  203.4782\n",
      "     12        \u001b[36m0.6113\u001b[0m       0.6437        1.0997  352.7898\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 16, the learning rate was 0.001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2964\u001b[0m       \u001b[32m0.1563\u001b[0m        \u001b[35m2.2855\u001b[0m  62.8376\n",
      "      2        \u001b[36m2.2500\u001b[0m       \u001b[32m0.2369\u001b[0m        \u001b[35m2.1857\u001b[0m  63.1041\n",
      "      3        \u001b[36m2.0977\u001b[0m       \u001b[32m0.2771\u001b[0m        \u001b[35m2.0253\u001b[0m  61.0745\n",
      "      4        \u001b[36m1.9956\u001b[0m       \u001b[32m0.3003\u001b[0m        \u001b[35m1.9668\u001b[0m  58.8770\n",
      "      5        \u001b[36m1.9464\u001b[0m       \u001b[32m0.3193\u001b[0m        \u001b[35m1.9265\u001b[0m  59.4622\n",
      "      6        \u001b[36m1.9105\u001b[0m       \u001b[32m0.3325\u001b[0m        \u001b[35m1.8931\u001b[0m  61.0843\n",
      "      7        \u001b[36m1.8791\u001b[0m       \u001b[32m0.3464\u001b[0m        \u001b[35m1.8611\u001b[0m  59.7554\n",
      "      8        \u001b[36m1.8484\u001b[0m       \u001b[32m0.3598\u001b[0m        \u001b[35m1.8307\u001b[0m  59.1445\n",
      "      9        \u001b[36m1.8205\u001b[0m       \u001b[32m0.3675\u001b[0m        \u001b[35m1.8045\u001b[0m  59.5986\n",
      "     10        \u001b[36m1.7975\u001b[0m       \u001b[32m0.3725\u001b[0m        \u001b[35m1.7836\u001b[0m  55.7545\n",
      "     11        \u001b[36m1.7786\u001b[0m       \u001b[32m0.3777\u001b[0m        \u001b[35m1.7670\u001b[0m  52.4581\n",
      "     12        \u001b[36m1.7627\u001b[0m       \u001b[32m0.3846\u001b[0m        \u001b[35m1.7533\u001b[0m  57.9407\n",
      "     13        \u001b[36m1.7489\u001b[0m       \u001b[32m0.3882\u001b[0m        \u001b[35m1.7418\u001b[0m  59.9380\n",
      "     14        \u001b[36m1.7367\u001b[0m       \u001b[32m0.3925\u001b[0m        \u001b[35m1.7317\u001b[0m  65.5651\n",
      "     15        \u001b[36m1.7257\u001b[0m       \u001b[32m0.3944\u001b[0m        \u001b[35m1.7224\u001b[0m  57.1700\n",
      "     16        \u001b[36m1.7155\u001b[0m       \u001b[32m0.3960\u001b[0m        \u001b[35m1.7138\u001b[0m  31.3681\n",
      "     17        \u001b[36m1.7055\u001b[0m       \u001b[32m0.3986\u001b[0m        \u001b[35m1.7051\u001b[0m  35.0293\n",
      "     18        \u001b[36m1.6956\u001b[0m       \u001b[32m0.4018\u001b[0m        \u001b[35m1.6961\u001b[0m  39.7325\n",
      "     19        \u001b[36m1.6852\u001b[0m       \u001b[32m0.4064\u001b[0m        \u001b[35m1.6861\u001b[0m  38.0291\n",
      "     20        \u001b[36m1.6740\u001b[0m       \u001b[32m0.4115\u001b[0m        \u001b[35m1.6748\u001b[0m  36.4835\n",
      "     21        \u001b[36m1.6617\u001b[0m       \u001b[32m0.4163\u001b[0m        \u001b[35m1.6620\u001b[0m  41.1977\n",
      "     22        \u001b[36m1.6481\u001b[0m       \u001b[32m0.4227\u001b[0m        \u001b[35m1.6480\u001b[0m  41.3113\n",
      "     23        \u001b[36m1.6336\u001b[0m       \u001b[32m0.4269\u001b[0m        \u001b[35m1.6332\u001b[0m  34.2660\n",
      "     24        \u001b[36m1.6189\u001b[0m       \u001b[32m0.4337\u001b[0m        \u001b[35m1.6187\u001b[0m  39.6896\n",
      "     25        \u001b[36m1.6043\u001b[0m       \u001b[32m0.4382\u001b[0m        \u001b[35m1.6046\u001b[0m  39.7966\n",
      "The channel was 32, the learning rate was 0.001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.2918\u001b[0m       \u001b[32m0.1775\u001b[0m        \u001b[35m2.2719\u001b[0m  100.1234\n",
      "      2        \u001b[36m2.1953\u001b[0m       \u001b[32m0.2770\u001b[0m        \u001b[35m2.0722\u001b[0m  98.2262\n",
      "      3        \u001b[36m1.9944\u001b[0m       \u001b[32m0.3046\u001b[0m        \u001b[35m1.9449\u001b[0m  103.1981\n",
      "      4        \u001b[36m1.9145\u001b[0m       \u001b[32m0.3318\u001b[0m        \u001b[35m1.8852\u001b[0m  104.1640\n",
      "      5        \u001b[36m1.8644\u001b[0m       \u001b[32m0.3492\u001b[0m        \u001b[35m1.8420\u001b[0m  104.9741\n",
      "      6        \u001b[36m1.8289\u001b[0m       \u001b[32m0.3612\u001b[0m        \u001b[35m1.8109\u001b[0m  105.7524\n",
      "      7        \u001b[36m1.8018\u001b[0m       \u001b[32m0.3664\u001b[0m        \u001b[35m1.7870\u001b[0m  105.2751\n",
      "      8        \u001b[36m1.7796\u001b[0m       \u001b[32m0.3738\u001b[0m        \u001b[35m1.7674\u001b[0m  102.9188\n",
      "      9        \u001b[36m1.7605\u001b[0m       \u001b[32m0.3808\u001b[0m        \u001b[35m1.7508\u001b[0m  100.9611\n",
      "     10        \u001b[36m1.7439\u001b[0m       \u001b[32m0.3855\u001b[0m        \u001b[35m1.7362\u001b[0m  105.1222\n",
      "     11        \u001b[36m1.7285\u001b[0m       \u001b[32m0.3919\u001b[0m        \u001b[35m1.7221\u001b[0m  105.9550\n",
      "     12        \u001b[36m1.7134\u001b[0m       \u001b[32m0.3981\u001b[0m        \u001b[35m1.7078\u001b[0m  106.2921\n",
      "     13        \u001b[36m1.6978\u001b[0m       \u001b[32m0.4039\u001b[0m        \u001b[35m1.6923\u001b[0m  105.0269\n",
      "     14        \u001b[36m1.6808\u001b[0m       \u001b[32m0.4117\u001b[0m        \u001b[35m1.6747\u001b[0m  101.3276\n",
      "     15        \u001b[36m1.6623\u001b[0m       \u001b[32m0.4192\u001b[0m        \u001b[35m1.6553\u001b[0m  106.9754\n",
      "     16        \u001b[36m1.6433\u001b[0m       \u001b[32m0.4245\u001b[0m        \u001b[35m1.6361\u001b[0m  106.4313\n",
      "     17        \u001b[36m1.6254\u001b[0m       \u001b[32m0.4321\u001b[0m        \u001b[35m1.6191\u001b[0m  106.3367\n",
      "     18        \u001b[36m1.6094\u001b[0m       \u001b[32m0.4386\u001b[0m        \u001b[35m1.6042\u001b[0m  105.7679\n",
      "     19        \u001b[36m1.5948\u001b[0m       \u001b[32m0.4425\u001b[0m        \u001b[35m1.5906\u001b[0m  105.5507\n",
      "     20        \u001b[36m1.5807\u001b[0m       \u001b[32m0.4490\u001b[0m        \u001b[35m1.5774\u001b[0m  79.0545\n",
      "     21        \u001b[36m1.5669\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m1.5643\u001b[0m  110.3573\n",
      "     22        \u001b[36m1.5530\u001b[0m       \u001b[32m0.4584\u001b[0m        \u001b[35m1.5511\u001b[0m  111.5549\n",
      "     23        \u001b[36m1.5390\u001b[0m       \u001b[32m0.4614\u001b[0m        \u001b[35m1.5379\u001b[0m  112.9123\n",
      "     24        \u001b[36m1.5251\u001b[0m       \u001b[32m0.4657\u001b[0m        \u001b[35m1.5249\u001b[0m  113.7903\n",
      "     25        \u001b[36m1.5112\u001b[0m       \u001b[32m0.4707\u001b[0m        \u001b[35m1.5122\u001b[0m  111.5942\n",
      "The channel was 64, the learning rate was 0.001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.2575\u001b[0m       \u001b[32m0.2347\u001b[0m        \u001b[35m2.1720\u001b[0m  284.8710\n",
      "      2        \u001b[36m2.0469\u001b[0m       \u001b[32m0.3039\u001b[0m        \u001b[35m1.9570\u001b[0m  271.1822\n",
      "      3        \u001b[36m1.9155\u001b[0m       \u001b[32m0.3392\u001b[0m        \u001b[35m1.8792\u001b[0m  257.0626\n",
      "      4        \u001b[36m1.8564\u001b[0m       \u001b[32m0.3573\u001b[0m        \u001b[35m1.8284\u001b[0m  252.7677\n",
      "      5        \u001b[36m1.8129\u001b[0m       \u001b[32m0.3730\u001b[0m        \u001b[35m1.7880\u001b[0m  253.8607\n",
      "      6        \u001b[36m1.7745\u001b[0m       \u001b[32m0.3881\u001b[0m        \u001b[35m1.7490\u001b[0m  303.3023\n",
      "      7        \u001b[36m1.7372\u001b[0m       \u001b[32m0.4042\u001b[0m        \u001b[35m1.7110\u001b[0m  222.1229\n",
      "      8        \u001b[36m1.7038\u001b[0m       \u001b[32m0.4136\u001b[0m        \u001b[35m1.6800\u001b[0m  241.7212\n",
      "      9        \u001b[36m1.6768\u001b[0m       \u001b[32m0.4232\u001b[0m        \u001b[35m1.6558\u001b[0m  202.0839\n",
      "     10        \u001b[36m1.6538\u001b[0m       \u001b[32m0.4310\u001b[0m        \u001b[35m1.6353\u001b[0m  263.5292\n",
      "     11        \u001b[36m1.6329\u001b[0m       \u001b[32m0.4373\u001b[0m        \u001b[35m1.6168\u001b[0m  265.5118\n",
      "     12        \u001b[36m1.6132\u001b[0m       \u001b[32m0.4438\u001b[0m        \u001b[35m1.5992\u001b[0m  251.3128\n",
      "     13        \u001b[36m1.5942\u001b[0m       \u001b[32m0.4494\u001b[0m        \u001b[35m1.5822\u001b[0m  226.1318\n",
      "     14        \u001b[36m1.5756\u001b[0m       \u001b[32m0.4549\u001b[0m        \u001b[35m1.5653\u001b[0m  241.7881\n",
      "     15        \u001b[36m1.5574\u001b[0m       \u001b[32m0.4595\u001b[0m        \u001b[35m1.5487\u001b[0m  192.4584\n",
      "     16        \u001b[36m1.5395\u001b[0m       \u001b[32m0.4634\u001b[0m        \u001b[35m1.5325\u001b[0m  194.0290\n",
      "     17        \u001b[36m1.5223\u001b[0m       \u001b[32m0.4689\u001b[0m        \u001b[35m1.5173\u001b[0m  198.1915\n",
      "     18        \u001b[36m1.5060\u001b[0m       \u001b[32m0.4732\u001b[0m        \u001b[35m1.5035\u001b[0m  214.3901\n",
      "     19        \u001b[36m1.4909\u001b[0m       \u001b[32m0.4765\u001b[0m        \u001b[35m1.4911\u001b[0m  214.4707\n",
      "     20        \u001b[36m1.4770\u001b[0m       \u001b[32m0.4790\u001b[0m        \u001b[35m1.4797\u001b[0m  213.0608\n",
      "     21        \u001b[36m1.4642\u001b[0m       \u001b[32m0.4803\u001b[0m        \u001b[35m1.4692\u001b[0m  212.3046\n",
      "     22        \u001b[36m1.4521\u001b[0m       \u001b[32m0.4821\u001b[0m        \u001b[35m1.4595\u001b[0m  213.4897\n",
      "     23        \u001b[36m1.4405\u001b[0m       \u001b[32m0.4861\u001b[0m        \u001b[35m1.4501\u001b[0m  213.9201\n",
      "     24        \u001b[36m1.4294\u001b[0m       \u001b[32m0.4909\u001b[0m        \u001b[35m1.4412\u001b[0m  213.1770\n",
      "     25        \u001b[36m1.4184\u001b[0m       \u001b[32m0.4937\u001b[0m        \u001b[35m1.4325\u001b[0m  214.2598\n",
      "The channel was 16, the learning rate was 0.001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m1.7436\u001b[0m       \u001b[32m0.4735\u001b[0m        \u001b[35m1.4827\u001b[0m  33.6238\n",
      "      2        \u001b[36m1.4139\u001b[0m       \u001b[32m0.5314\u001b[0m        \u001b[35m1.3268\u001b[0m  34.9068\n",
      "      3        \u001b[36m1.2470\u001b[0m       \u001b[32m0.5739\u001b[0m        \u001b[35m1.2012\u001b[0m  34.2287\n",
      "      4        \u001b[36m1.1048\u001b[0m       \u001b[32m0.5939\u001b[0m        \u001b[35m1.1564\u001b[0m  33.9101\n",
      "      5        \u001b[36m0.9872\u001b[0m       \u001b[32m0.6057\u001b[0m        \u001b[35m1.1545\u001b[0m  33.7875\n",
      "      6        \u001b[36m0.8806\u001b[0m       \u001b[32m0.6068\u001b[0m        1.1838  33.9868\n",
      "      7        \u001b[36m0.7912\u001b[0m       0.6066        1.2303  33.8943\n",
      "      8        \u001b[36m0.7121\u001b[0m       0.6018        1.3180  33.9959\n",
      "      9        \u001b[36m0.6346\u001b[0m       0.5843        1.5201  34.5033\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 32, the learning rate was 0.001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m1.6392\u001b[0m       \u001b[32m0.5129\u001b[0m        \u001b[35m1.3716\u001b[0m  79.5216\n",
      "      2        \u001b[36m1.2768\u001b[0m       \u001b[32m0.5762\u001b[0m        \u001b[35m1.1864\u001b[0m  80.1609\n",
      "      3        \u001b[36m1.0843\u001b[0m       \u001b[32m0.5977\u001b[0m        \u001b[35m1.1543\u001b[0m  81.0517\n",
      "      4        \u001b[36m0.9439\u001b[0m       \u001b[32m0.6044\u001b[0m        1.1950  80.9044\n",
      "      5        \u001b[36m0.8090\u001b[0m       \u001b[32m0.6082\u001b[0m        1.2552  81.2396\n",
      "      6        \u001b[36m0.6837\u001b[0m       0.5862        1.4491  80.4444\n",
      "      7        \u001b[36m0.5770\u001b[0m       0.5707        1.6861  80.3253\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 64, the learning rate was 0.001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m1.5455\u001b[0m       \u001b[32m0.5606\u001b[0m        \u001b[35m1.2410\u001b[0m  215.2249\n",
      "      2        \u001b[36m1.1250\u001b[0m       \u001b[32m0.6300\u001b[0m        \u001b[35m1.0641\u001b[0m  218.1638\n",
      "      3        \u001b[36m0.9070\u001b[0m       \u001b[32m0.6414\u001b[0m        \u001b[35m1.0592\u001b[0m  218.0134\n",
      "      4        \u001b[36m0.7451\u001b[0m       0.6298        1.1461  220.1412\n",
      "      5        \u001b[36m0.6064\u001b[0m       0.6173        1.3049  217.9364\n",
      "      6        \u001b[36m0.4885\u001b[0m       0.6053        1.4677  218.7542\n",
      "      7        \u001b[36m0.4168\u001b[0m       0.6066        1.5865  220.4605\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 16, the learning rate was 0.01 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.0554\u001b[0m       \u001b[32m0.3064\u001b[0m        \u001b[35m1.9374\u001b[0m  32.1266\n",
      "      2        \u001b[36m1.7919\u001b[0m       \u001b[32m0.3784\u001b[0m        \u001b[35m1.7518\u001b[0m  31.9039\n",
      "      3        \u001b[36m1.7046\u001b[0m       \u001b[32m0.4043\u001b[0m        \u001b[35m1.6787\u001b[0m  32.3028\n",
      "      4        \u001b[36m1.6251\u001b[0m       \u001b[32m0.4372\u001b[0m        \u001b[35m1.5879\u001b[0m  31.8986\n",
      "      5        \u001b[36m1.5426\u001b[0m       \u001b[32m0.4630\u001b[0m        \u001b[35m1.5165\u001b[0m  32.4555\n",
      "      6        \u001b[36m1.4749\u001b[0m       \u001b[32m0.4854\u001b[0m        \u001b[35m1.4505\u001b[0m  32.0101\n",
      "      7        \u001b[36m1.4209\u001b[0m       \u001b[32m0.5007\u001b[0m        \u001b[35m1.3991\u001b[0m  32.1931\n",
      "      8        \u001b[36m1.3768\u001b[0m       \u001b[32m0.5098\u001b[0m        \u001b[35m1.3647\u001b[0m  32.3143\n",
      "      9        \u001b[36m1.3407\u001b[0m       \u001b[32m0.5189\u001b[0m        \u001b[35m1.3422\u001b[0m  34.0823\n",
      "     10        \u001b[36m1.3103\u001b[0m       \u001b[32m0.5260\u001b[0m        \u001b[35m1.3247\u001b[0m  32.7837\n",
      "     11        \u001b[36m1.2837\u001b[0m       \u001b[32m0.5310\u001b[0m        \u001b[35m1.3127\u001b[0m  32.8594\n",
      "     12        \u001b[36m1.2589\u001b[0m       \u001b[32m0.5351\u001b[0m        \u001b[35m1.3050\u001b[0m  32.8592\n",
      "     13        \u001b[36m1.2350\u001b[0m       \u001b[32m0.5375\u001b[0m        \u001b[35m1.2950\u001b[0m  32.2958\n",
      "     14        \u001b[36m1.2113\u001b[0m       \u001b[32m0.5429\u001b[0m        \u001b[35m1.2863\u001b[0m  32.6479\n",
      "     15        \u001b[36m1.1864\u001b[0m       \u001b[32m0.5448\u001b[0m        \u001b[35m1.2753\u001b[0m  32.5674\n",
      "     16        \u001b[36m1.1600\u001b[0m       \u001b[32m0.5510\u001b[0m        \u001b[35m1.2620\u001b[0m  32.5912\n",
      "     17        \u001b[36m1.1338\u001b[0m       \u001b[32m0.5579\u001b[0m        \u001b[35m1.2510\u001b[0m  32.1261\n",
      "     18        \u001b[36m1.1076\u001b[0m       \u001b[32m0.5624\u001b[0m        \u001b[35m1.2430\u001b[0m  33.1683\n",
      "     19        \u001b[36m1.0813\u001b[0m       \u001b[32m0.5708\u001b[0m        \u001b[35m1.2259\u001b[0m  32.5658\n",
      "     20        \u001b[36m1.0546\u001b[0m       \u001b[32m0.5763\u001b[0m        \u001b[35m1.2112\u001b[0m  32.9377\n",
      "     21        \u001b[36m1.0271\u001b[0m       \u001b[32m0.5802\u001b[0m        \u001b[35m1.2013\u001b[0m  32.5382\n",
      "     22        \u001b[36m0.9991\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m1.1914\u001b[0m  32.8069\n",
      "     23        \u001b[36m0.9713\u001b[0m       \u001b[32m0.5882\u001b[0m        \u001b[35m1.1885\u001b[0m  33.4357\n",
      "     24        \u001b[36m0.9440\u001b[0m       \u001b[32m0.5933\u001b[0m        \u001b[35m1.1867\u001b[0m  32.8244\n",
      "     25        \u001b[36m0.9175\u001b[0m       \u001b[32m0.5937\u001b[0m        1.1897  33.5969\n",
      "The channel was 32, the learning rate was 0.01 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m1.9882\u001b[0m       \u001b[32m0.3503\u001b[0m        \u001b[35m1.8243\u001b[0m  78.8034\n",
      "      2        \u001b[36m1.7197\u001b[0m       \u001b[32m0.4227\u001b[0m        \u001b[35m1.6394\u001b[0m  79.1140\n",
      "      3        \u001b[36m1.5920\u001b[0m       \u001b[32m0.4604\u001b[0m        \u001b[35m1.5231\u001b[0m  78.4201\n",
      "      4        \u001b[36m1.4871\u001b[0m       \u001b[32m0.4865\u001b[0m        \u001b[35m1.4378\u001b[0m  77.9095\n",
      "      5        \u001b[36m1.4048\u001b[0m       \u001b[32m0.5134\u001b[0m        \u001b[35m1.3671\u001b[0m  79.3930\n",
      "      6        \u001b[36m1.3368\u001b[0m       \u001b[32m0.5274\u001b[0m        \u001b[35m1.3144\u001b[0m  78.3532\n",
      "      7        \u001b[36m1.2702\u001b[0m       \u001b[32m0.5384\u001b[0m        \u001b[35m1.2814\u001b[0m  78.9115\n",
      "      8        \u001b[36m1.2169\u001b[0m       \u001b[32m0.5473\u001b[0m        \u001b[35m1.2562\u001b[0m  78.8646\n",
      "      9        \u001b[36m1.1693\u001b[0m       \u001b[32m0.5588\u001b[0m        \u001b[35m1.2340\u001b[0m  79.3294\n",
      "     10        \u001b[36m1.1236\u001b[0m       \u001b[32m0.5699\u001b[0m        \u001b[35m1.2112\u001b[0m  79.0200\n",
      "     11        \u001b[36m1.0788\u001b[0m       \u001b[32m0.5806\u001b[0m        \u001b[35m1.1873\u001b[0m  79.5395\n",
      "     12        \u001b[36m1.0351\u001b[0m       \u001b[32m0.5904\u001b[0m        \u001b[35m1.1709\u001b[0m  79.4168\n",
      "     13        \u001b[36m0.9931\u001b[0m       \u001b[32m0.5929\u001b[0m        \u001b[35m1.1610\u001b[0m  80.7001\n",
      "     14        \u001b[36m0.9530\u001b[0m       \u001b[32m0.6008\u001b[0m        \u001b[35m1.1532\u001b[0m  79.4426\n",
      "     15        \u001b[36m0.9143\u001b[0m       \u001b[32m0.6039\u001b[0m        \u001b[35m1.1506\u001b[0m  79.4936\n",
      "     16        \u001b[36m0.8764\u001b[0m       \u001b[32m0.6059\u001b[0m        1.1516  79.8378\n",
      "     17        \u001b[36m0.8392\u001b[0m       \u001b[32m0.6081\u001b[0m        1.1577  81.5592\n",
      "     18        \u001b[36m0.8021\u001b[0m       \u001b[32m0.6086\u001b[0m        1.1680  79.7244\n",
      "     19        \u001b[36m0.7651\u001b[0m       \u001b[32m0.6106\u001b[0m        1.1833  80.8649\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 64, the learning rate was 0.01 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m1.9238\u001b[0m       \u001b[32m0.3923\u001b[0m        \u001b[35m1.7129\u001b[0m  213.7789\n",
      "      2        \u001b[36m1.6223\u001b[0m       \u001b[32m0.4537\u001b[0m        \u001b[35m1.5411\u001b[0m  216.7653\n",
      "      3        \u001b[36m1.4901\u001b[0m       \u001b[32m0.4887\u001b[0m        \u001b[35m1.4371\u001b[0m  216.1997\n",
      "      4        \u001b[36m1.4097\u001b[0m       \u001b[32m0.5048\u001b[0m        \u001b[35m1.3796\u001b[0m  218.8107\n",
      "      5        \u001b[36m1.3467\u001b[0m       \u001b[32m0.5199\u001b[0m        \u001b[35m1.3309\u001b[0m  216.5749\n",
      "      6        \u001b[36m1.2840\u001b[0m       \u001b[32m0.5423\u001b[0m        \u001b[35m1.2776\u001b[0m  214.9383\n",
      "      7        \u001b[36m1.2187\u001b[0m       \u001b[32m0.5589\u001b[0m        \u001b[35m1.2334\u001b[0m  215.9890\n",
      "      8        \u001b[36m1.1613\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m1.1945\u001b[0m  216.7445\n",
      "      9        \u001b[36m1.1131\u001b[0m       \u001b[32m0.5865\u001b[0m        \u001b[35m1.1653\u001b[0m  216.2992\n",
      "     10        \u001b[36m1.0708\u001b[0m       \u001b[32m0.5958\u001b[0m        \u001b[35m1.1396\u001b[0m  217.9955\n",
      "     11        \u001b[36m1.0329\u001b[0m       \u001b[32m0.6027\u001b[0m        \u001b[35m1.1224\u001b[0m  228.4997\n",
      "     12        \u001b[36m0.9984\u001b[0m       \u001b[32m0.6096\u001b[0m        \u001b[35m1.1077\u001b[0m  224.0026\n",
      "     13        \u001b[36m0.9654\u001b[0m       \u001b[32m0.6143\u001b[0m        \u001b[35m1.0994\u001b[0m  216.9344\n",
      "     14        \u001b[36m0.9331\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m1.0930\u001b[0m  236.4126\n",
      "     15        \u001b[36m0.9002\u001b[0m       \u001b[32m0.6204\u001b[0m        \u001b[35m1.0890\u001b[0m  247.5127\n",
      "     16        \u001b[36m0.8663\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m1.0879\u001b[0m  242.1076\n",
      "     17        \u001b[36m0.8310\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m1.0874\u001b[0m  226.0298\n",
      "     18        \u001b[36m0.7947\u001b[0m       \u001b[32m0.6259\u001b[0m        1.0890  216.5611\n",
      "     19        \u001b[36m0.7578\u001b[0m       \u001b[32m0.6282\u001b[0m        1.0964  217.5583\n",
      "     20        \u001b[36m0.7206\u001b[0m       \u001b[32m0.6294\u001b[0m        1.1091  254.2584\n",
      "     21        \u001b[36m0.6830\u001b[0m       0.6274        1.1272  260.1418\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 16, the learning rate was 0.01 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.3163\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3034\u001b[0m  50.7011\n",
      "      2        \u001b[36m2.3038\u001b[0m       0.1000        2.3035  47.4422\n",
      "      3        2.3039       0.1000        2.3035  42.5227\n",
      "      4        2.3039       0.1000        2.3035  41.7330\n",
      "      5        2.3039       0.1000        2.3035  38.6801\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 32, the learning rate was 0.01 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.3153\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3035\u001b[0m  89.8181\n",
      "      2        \u001b[36m2.3039\u001b[0m       0.1000        2.3035  90.8093\n",
      "      3        2.3039       0.1000        2.3035  123.9652\n",
      "      4        2.3039       0.1000        2.3035  135.9307\n",
      "      5        2.3039       0.1000        2.3035  118.6586\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 64, the learning rate was 0.01 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.7192\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3034\u001b[0m  262.2795\n",
      "      2        \u001b[36m2.3038\u001b[0m       0.1000        2.3035  242.4639\n",
      "      3        2.3039       0.1000        2.3035  280.0173\n",
      "      4        2.3039       0.1000        2.3035  268.4130\n",
      "      5        2.3039       0.1000        2.3035  440.0961\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "# implement hyperparameters, you can select and modify the hyperparameters by yourself here.\n",
    "\n",
    "optimize = [torch.optim.SGD, torch.optim.Adam]\n",
    "learning_rate = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "channel = [16,32,64]\n",
    "\n",
    "\n",
    "train_data_normalized = torch.Tensor(train.data/255)\n",
    "train_data_normalized = train_data_normalized.permute(0,3,1,2)\n",
    "\n",
    "for l in learning_rate:\n",
    "  for o in optimize: \n",
    "    for c in channel:\n",
    "      print(f'The channel was {c}, the learning rate was {l} and the optimizer was {str(o)}')\n",
    "\n",
    "      cnn = CNN(channels = c)\n",
    "      \n",
    "      model = skorch.NeuralNetClassifier(cnn, criterion=torch.nn.CrossEntropyLoss,\n",
    "                                   device=\"cpu\",\n",
    "                                   optimizer=o,\n",
    "                                  # optimizer__momentum=0.90,\n",
    "                                   lr=l,\n",
    "                                   max_epochs=25,\n",
    "                                   batch_size=64,\n",
    "                                   callbacks=[skorch.callbacks.EarlyStopping(lower_is_better=True)])\n",
    "      # implement input normalization & type cast here \n",
    "      model.fit(train_data_normalized, np.asarray(train.targets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-EHKzozkRbD"
   },
   "source": [
    "Write down **validation accuracy** of your model under different hyperparameter settings. Note the validation set is automatically split by Skorch during `model.fit()`.\n",
    "\n",
    "\n",
    "| #channel for each layer \\ optimizer | SGD   | Adam  |\n",
    "|-------------------------------------|-------|-------|\n",
    "|           (16,16,16)                | 62.64 | 66.00 |\n",
    "|           (32,32,32)                | 67.89 | 72.11 |\n",
    "|           (64,64,64)                | 63.22 | 65.60 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "go55LVSJd-vG"
   },
   "source": [
    "### 2) Full CNN implementation (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6G0eCj6OmOEE"
   },
   "source": [
    "Based on the CNN in the previous question, implement a full CNN model with max pooling layer.\n",
    "\n",
    "- Add a max pooling layer after each convolutional layer.\n",
    "- Each max pooling layer has a kernel size of 2 and a stride of 2.\n",
    "\n",
    "Please implement this model in the following section. The hyperparameters is then be tuned and fill the results in the table. You are also required to complete the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMrKGlMQhCa0"
   },
   "source": [
    "#### a) Implement max pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2INt6P3Myd1"
   },
   "source": [
    "Similar to the CNN implementation in previous question, implement max pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHu3Ic2dM1S9"
   },
   "outputs": [],
   "source": [
    "class CNN_MaxPool(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(CNN_MaxPool, self).__init__()\n",
    "    # implement parameter definitions here\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    self.conv1 = nn.Conv2d(3,512,3,padding=1)\n",
    "    self.conv2 = nn.Conv2d(512,512,3,padding=1)\n",
    "    self.conv3 = nn.Conv2d(512,512,3,padding=1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.fcl = nn.Linear(512*4*4,10)\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "  \n",
    "  def forward(self, images):\n",
    "    # implement the forward function here\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    images = self.pool(F.relu(self.conv1(images)))\n",
    "    images = self.pool(F.relu(self.conv2(images)))\n",
    "    images = self.pool(F.relu(self.conv3(images)))\n",
    "    images = images.view(images.size(0), -1)\n",
    "    images = self.fcl(images)\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-A6AEOoigq68"
   },
   "source": [
    "#### b) Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drH4MHSVNqwz"
   },
   "source": [
    "Based on the better optimizer found in the previous problem, we can tune the number of channels and learning rate for best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "7povzg-4Nhrr",
    "outputId": "edff26c7-6f98-49be-cac4-9e6ef53c83c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel was 16, the learning rate was 1e-05\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.9620\u001b[0m       \u001b[32m0.4077\u001b[0m        \u001b[35m1.7026\u001b[0m  2015.3576\n",
      "      2        \u001b[36m1.6225\u001b[0m       \u001b[32m0.4595\u001b[0m        \u001b[35m1.5351\u001b[0m  2181.7414\n",
      "      3        \u001b[36m1.4975\u001b[0m       \u001b[32m0.4886\u001b[0m        \u001b[35m1.4461\u001b[0m  2189.5115\n",
      "      4        \u001b[36m1.4178\u001b[0m       \u001b[32m0.5118\u001b[0m        \u001b[35m1.3862\u001b[0m  2183.9949\n",
      "      5        \u001b[36m1.3609\u001b[0m       \u001b[32m0.5283\u001b[0m        \u001b[35m1.3418\u001b[0m  2181.5302\n",
      "      6        \u001b[36m1.3178\u001b[0m       \u001b[32m0.5435\u001b[0m        \u001b[35m1.3058\u001b[0m  2182.7197\n",
      "      7        \u001b[36m1.2821\u001b[0m       \u001b[32m0.5561\u001b[0m        \u001b[35m1.2747\u001b[0m  2183.1216\n",
      "      8        \u001b[36m1.2505\u001b[0m       \u001b[32m0.5653\u001b[0m        \u001b[35m1.2466\u001b[0m  2175.7946\n",
      "      9        \u001b[36m1.2216\u001b[0m       \u001b[32m0.5737\u001b[0m        \u001b[35m1.2212\u001b[0m  2122.4000\n",
      "     10        \u001b[36m1.1948\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m1.1977\u001b[0m  2116.9122\n",
      "     11        \u001b[36m1.1697\u001b[0m       \u001b[32m0.5895\u001b[0m        \u001b[35m1.1760\u001b[0m  2111.7452\n",
      "     12        \u001b[36m1.1462\u001b[0m       \u001b[32m0.5974\u001b[0m        \u001b[35m1.1558\u001b[0m  2133.8165\n",
      "     13        \u001b[36m1.1239\u001b[0m       \u001b[32m0.6046\u001b[0m        \u001b[35m1.1369\u001b[0m  2165.6519\n",
      "     14        \u001b[36m1.1029\u001b[0m       \u001b[32m0.6119\u001b[0m        \u001b[35m1.1189\u001b[0m  2179.4310\n",
      "     15        \u001b[36m1.0829\u001b[0m       \u001b[32m0.6195\u001b[0m        \u001b[35m1.1020\u001b[0m  2176.8308\n",
      "     16        \u001b[36m1.0637\u001b[0m       \u001b[32m0.6238\u001b[0m        \u001b[35m1.0863\u001b[0m  2186.6272\n",
      "     17        \u001b[36m1.0455\u001b[0m       \u001b[32m0.6263\u001b[0m        \u001b[35m1.0712\u001b[0m  2190.6645\n",
      "     18        \u001b[36m1.0280\u001b[0m       \u001b[32m0.6311\u001b[0m        \u001b[35m1.0570\u001b[0m  2132.4965\n",
      "     19        \u001b[36m1.0113\u001b[0m       \u001b[32m0.6364\u001b[0m        \u001b[35m1.0436\u001b[0m  2491.9667\n",
      "     20        \u001b[36m0.9951\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m1.0309\u001b[0m  2022.1192\n",
      "     21        \u001b[36m0.9796\u001b[0m       \u001b[32m0.6457\u001b[0m        \u001b[35m1.0188\u001b[0m  1885.7328\n",
      "     22        \u001b[36m0.9648\u001b[0m       \u001b[32m0.6514\u001b[0m        \u001b[35m1.0072\u001b[0m  1745.3710\n",
      "     23        \u001b[36m0.9505\u001b[0m       \u001b[32m0.6555\u001b[0m        \u001b[35m0.9963\u001b[0m  1745.1618\n",
      "     24        \u001b[36m0.9367\u001b[0m       \u001b[32m0.6584\u001b[0m        \u001b[35m0.9858\u001b[0m  1770.0926\n",
      "     25        \u001b[36m0.9235\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.9759\u001b[0m  2212.5278\n",
      "The channel was 32, the learning rate was 1e-05\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.9730\u001b[0m       \u001b[32m0.4036\u001b[0m        \u001b[35m1.7164\u001b[0m  1949.7775\n",
      "      2        \u001b[36m1.6381\u001b[0m       \u001b[32m0.4532\u001b[0m        \u001b[35m1.5527\u001b[0m  1489.9995\n",
      "      3        \u001b[36m1.5127\u001b[0m       \u001b[32m0.4858\u001b[0m        \u001b[35m1.4591\u001b[0m  1483.2545\n",
      "      4        \u001b[36m1.4310\u001b[0m       \u001b[32m0.5029\u001b[0m        \u001b[35m1.3969\u001b[0m  1962.5577\n",
      "      5        \u001b[36m1.3724\u001b[0m       \u001b[32m0.5189\u001b[0m        \u001b[35m1.3522\u001b[0m  1624.4438\n",
      "      6        \u001b[36m1.3286\u001b[0m       \u001b[32m0.5328\u001b[0m        \u001b[35m1.3165\u001b[0m  1860.1606\n",
      "      7        \u001b[36m1.2928\u001b[0m       \u001b[32m0.5456\u001b[0m        \u001b[35m1.2858\u001b[0m  2097.1347\n",
      "      8        \u001b[36m1.2615\u001b[0m       \u001b[32m0.5581\u001b[0m        \u001b[35m1.2582\u001b[0m  1860.9127\n",
      "      9        \u001b[36m1.2330\u001b[0m       \u001b[32m0.5702\u001b[0m        \u001b[35m1.2329\u001b[0m  1925.6908\n",
      "     10        \u001b[36m1.2065\u001b[0m       \u001b[32m0.5782\u001b[0m        \u001b[35m1.2097\u001b[0m  1926.7113\n",
      "     11        \u001b[36m1.1819\u001b[0m       \u001b[32m0.5853\u001b[0m        \u001b[35m1.1880\u001b[0m  1904.7657\n",
      "     12        \u001b[36m1.1586\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.1679\u001b[0m  2011.2623\n",
      "     13        \u001b[36m1.1366\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m1.1489\u001b[0m  1861.9987\n",
      "     14        \u001b[36m1.1157\u001b[0m       \u001b[32m0.6052\u001b[0m        \u001b[35m1.1312\u001b[0m  1962.1067\n",
      "     15        \u001b[36m1.0958\u001b[0m       \u001b[32m0.6104\u001b[0m        \u001b[35m1.1144\u001b[0m  2043.5940\n",
      "     16        \u001b[36m1.0768\u001b[0m       \u001b[32m0.6162\u001b[0m        \u001b[35m1.0988\u001b[0m  2634.7108\n",
      "     17        \u001b[36m1.0587\u001b[0m       \u001b[32m0.6199\u001b[0m        \u001b[35m1.0841\u001b[0m  2675.6508\n",
      "     18        \u001b[36m1.0413\u001b[0m       \u001b[32m0.6253\u001b[0m        \u001b[35m1.0700\u001b[0m  2109.1479\n",
      "     19        \u001b[36m1.0246\u001b[0m       \u001b[32m0.6296\u001b[0m        \u001b[35m1.0566\u001b[0m  2029.2728\n",
      "     20        \u001b[36m1.0086\u001b[0m       \u001b[32m0.6341\u001b[0m        \u001b[35m1.0440\u001b[0m  2033.8819\n",
      "     21        \u001b[36m0.9933\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m1.0322\u001b[0m  2029.2635\n",
      "     22        \u001b[36m0.9785\u001b[0m       \u001b[32m0.6440\u001b[0m        \u001b[35m1.0208\u001b[0m  2028.9265\n",
      "     23        \u001b[36m0.9644\u001b[0m       \u001b[32m0.6473\u001b[0m        \u001b[35m1.0100\u001b[0m  2025.9630\n",
      "     24        \u001b[36m0.9507\u001b[0m       \u001b[32m0.6506\u001b[0m        \u001b[35m0.9996\u001b[0m  2036.2984\n",
      "     25        \u001b[36m0.9375\u001b[0m       \u001b[32m0.6535\u001b[0m        \u001b[35m0.9899\u001b[0m  2012.0991\n",
      "The channel was 64, the learning rate was 1e-05\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.9789\u001b[0m       \u001b[32m0.4005\u001b[0m        \u001b[35m1.7277\u001b[0m  1985.6530\n",
      "      2        \u001b[36m1.6450\u001b[0m       \u001b[32m0.4538\u001b[0m        \u001b[35m1.5547\u001b[0m  1985.4058\n",
      "      3        \u001b[36m1.5141\u001b[0m       \u001b[32m0.4847\u001b[0m        \u001b[35m1.4577\u001b[0m  1987.3407\n",
      "      4        \u001b[36m1.4299\u001b[0m       \u001b[32m0.5104\u001b[0m        \u001b[35m1.3948\u001b[0m  1992.3526\n",
      "      5        \u001b[36m1.3713\u001b[0m       \u001b[32m0.5266\u001b[0m        \u001b[35m1.3502\u001b[0m  1986.3687\n",
      "      6        \u001b[36m1.3274\u001b[0m       \u001b[32m0.5381\u001b[0m        \u001b[35m1.3144\u001b[0m  2005.1232\n",
      "      7        \u001b[36m1.2912\u001b[0m       \u001b[32m0.5513\u001b[0m        \u001b[35m1.2838\u001b[0m  2030.5202\n",
      "      8        \u001b[36m1.2592\u001b[0m       \u001b[32m0.5605\u001b[0m        \u001b[35m1.2562\u001b[0m  2034.0302\n",
      "      9        \u001b[36m1.2302\u001b[0m       \u001b[32m0.5709\u001b[0m        \u001b[35m1.2308\u001b[0m  2040.9535\n",
      "     10        \u001b[36m1.2033\u001b[0m       \u001b[32m0.5802\u001b[0m        \u001b[35m1.2074\u001b[0m  3005.5707\n",
      "     11        \u001b[36m1.1782\u001b[0m       \u001b[32m0.5881\u001b[0m        \u001b[35m1.1854\u001b[0m  3138.7492\n",
      "     12        \u001b[36m1.1547\u001b[0m       \u001b[32m0.5942\u001b[0m        \u001b[35m1.1648\u001b[0m  2517.8228\n",
      "     13        \u001b[36m1.1324\u001b[0m       \u001b[32m0.6005\u001b[0m        \u001b[35m1.1459\u001b[0m  1770.9409\n",
      "     14        \u001b[36m1.1113\u001b[0m       \u001b[32m0.6077\u001b[0m        \u001b[35m1.1280\u001b[0m  1777.9515\n",
      "     15        \u001b[36m1.0913\u001b[0m       \u001b[32m0.6124\u001b[0m        \u001b[35m1.1113\u001b[0m  1827.6349\n",
      "     16        \u001b[36m1.0723\u001b[0m       \u001b[32m0.6176\u001b[0m        \u001b[35m1.0952\u001b[0m  1772.7285\n",
      "     17        \u001b[36m1.0541\u001b[0m       \u001b[32m0.6233\u001b[0m        \u001b[35m1.0803\u001b[0m  1825.2955\n",
      "     18        \u001b[36m1.0368\u001b[0m       \u001b[32m0.6281\u001b[0m        \u001b[35m1.0660\u001b[0m  1796.1912\n",
      "     19        \u001b[36m1.0201\u001b[0m       \u001b[32m0.6321\u001b[0m        \u001b[35m1.0526\u001b[0m  1692.3421\n",
      "     20        \u001b[36m1.0042\u001b[0m       \u001b[32m0.6363\u001b[0m        \u001b[35m1.0400\u001b[0m  1692.9635\n",
      "     21        \u001b[36m0.9889\u001b[0m       \u001b[32m0.6421\u001b[0m        \u001b[35m1.0281\u001b[0m  1839.3732\n",
      "     22        \u001b[36m0.9742\u001b[0m       \u001b[32m0.6457\u001b[0m        \u001b[35m1.0168\u001b[0m  2211.6594\n",
      "     23        \u001b[36m0.9601\u001b[0m       \u001b[32m0.6494\u001b[0m        \u001b[35m1.0062\u001b[0m  1855.1671\n",
      "     24        \u001b[36m0.9465\u001b[0m       \u001b[32m0.6535\u001b[0m        \u001b[35m0.9959\u001b[0m  1824.7757\n",
      "     25        \u001b[36m0.9334\u001b[0m       \u001b[32m0.6573\u001b[0m        \u001b[35m0.9862\u001b[0m  1802.4270\n",
      "The channel was 16, the learning rate was 0.0001\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.6355\u001b[0m       \u001b[32m0.5304\u001b[0m        \u001b[35m1.3180\u001b[0m  2770.2951\n",
      "      2        \u001b[36m1.2318\u001b[0m       \u001b[32m0.6103\u001b[0m        \u001b[35m1.1098\u001b[0m  2611.8159\n",
      "      3        \u001b[36m1.0593\u001b[0m       \u001b[32m0.6553\u001b[0m        \u001b[35m0.9850\u001b[0m  1812.2924\n",
      "      4        \u001b[36m0.9358\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.9174\u001b[0m  1520.0275\n",
      "      5        \u001b[36m0.8430\u001b[0m       \u001b[32m0.6907\u001b[0m        \u001b[35m0.8806\u001b[0m  2006.2764\n",
      "      6        \u001b[36m0.7693\u001b[0m       \u001b[32m0.7014\u001b[0m        \u001b[35m0.8549\u001b[0m  1987.1612\n",
      "      7        \u001b[36m0.7071\u001b[0m       \u001b[32m0.7083\u001b[0m        \u001b[35m0.8357\u001b[0m  2720.4578\n",
      "      8        \u001b[36m0.6510\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.8158\u001b[0m  2284.5833\n",
      "      9        \u001b[36m0.5984\u001b[0m       \u001b[32m0.7265\u001b[0m        \u001b[35m0.7918\u001b[0m  1764.6349\n",
      "     10        \u001b[36m0.5477\u001b[0m       \u001b[32m0.7343\u001b[0m        \u001b[35m0.7780\u001b[0m  1683.3413\n",
      "     11        \u001b[36m0.4995\u001b[0m       \u001b[32m0.7381\u001b[0m        \u001b[35m0.7768\u001b[0m  1904.5913\n",
      "     12        \u001b[36m0.4555\u001b[0m       \u001b[32m0.7387\u001b[0m        0.7776  1866.6369\n",
      "     13        \u001b[36m0.4127\u001b[0m       0.7384        0.7880  1862.4910\n",
      "     14        \u001b[36m0.3709\u001b[0m       0.7325        0.8154  1875.5805\n",
      "     15        \u001b[36m0.3301\u001b[0m       0.7300        0.8527  2020.2487\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 32, the learning rate was 0.0001\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.6505\u001b[0m       \u001b[32m0.5274\u001b[0m        \u001b[35m1.3286\u001b[0m  2016.2083\n",
      "      2        \u001b[36m1.2360\u001b[0m       \u001b[32m0.6101\u001b[0m        \u001b[35m1.1119\u001b[0m  2046.6934\n",
      "      3        \u001b[36m1.0577\u001b[0m       \u001b[32m0.6581\u001b[0m        \u001b[35m0.9798\u001b[0m  2024.6255\n",
      "      4        \u001b[36m0.9334\u001b[0m       \u001b[32m0.6789\u001b[0m        \u001b[35m0.9123\u001b[0m  2022.7825\n",
      "      5        \u001b[36m0.8398\u001b[0m       \u001b[32m0.6931\u001b[0m        \u001b[35m0.8746\u001b[0m  2029.5375\n",
      "      6        \u001b[36m0.7639\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.8480\u001b[0m  2022.9922\n",
      "      7        \u001b[36m0.6994\u001b[0m       \u001b[32m0.7123\u001b[0m        \u001b[35m0.8289\u001b[0m  1999.5237\n",
      "      8        \u001b[36m0.6407\u001b[0m       \u001b[32m0.7202\u001b[0m        \u001b[35m0.8144\u001b[0m  1841.0888\n",
      "      9        \u001b[36m0.5853\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.8062\u001b[0m  1830.9262\n",
      "     10        \u001b[36m0.5335\u001b[0m       \u001b[32m0.7293\u001b[0m        \u001b[35m0.8037\u001b[0m  1830.7831\n",
      "     11        \u001b[36m0.4839\u001b[0m       \u001b[32m0.7342\u001b[0m        0.8082  1844.9272\n",
      "     12        \u001b[36m0.4376\u001b[0m       \u001b[32m0.7346\u001b[0m        0.8202  1890.5180\n",
      "     13        \u001b[36m0.3938\u001b[0m       \u001b[32m0.7356\u001b[0m        0.8305  1852.2313\n",
      "     14        \u001b[36m0.3516\u001b[0m       \u001b[32m0.7374\u001b[0m        0.8523  1855.6431\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 64, the learning rate was 0.0001\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.6386\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m1.3020\u001b[0m  2788.4585\n",
      "      2        \u001b[36m1.2156\u001b[0m       \u001b[32m0.6161\u001b[0m        \u001b[35m1.0923\u001b[0m  1982.6056\n",
      "      3        \u001b[36m1.0390\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m0.9749\u001b[0m  1952.9520\n",
      "      4        \u001b[36m0.9179\u001b[0m       \u001b[32m0.6826\u001b[0m        \u001b[35m0.9064\u001b[0m  1991.6278\n",
      "      5        \u001b[36m0.8271\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.8686\u001b[0m  1930.3556\n",
      "      6        \u001b[36m0.7540\u001b[0m       \u001b[32m0.7066\u001b[0m        \u001b[35m0.8407\u001b[0m  2052.6165\n",
      "      7        \u001b[36m0.6913\u001b[0m       \u001b[32m0.7151\u001b[0m        \u001b[35m0.8192\u001b[0m  1921.7194\n",
      "      8        \u001b[36m0.6339\u001b[0m       \u001b[32m0.7215\u001b[0m        \u001b[35m0.8040\u001b[0m  1912.6408\n",
      "      9        \u001b[36m0.5806\u001b[0m       \u001b[32m0.7259\u001b[0m        \u001b[35m0.7941\u001b[0m  1920.7272\n",
      "     10        \u001b[36m0.5306\u001b[0m       \u001b[32m0.7316\u001b[0m        \u001b[35m0.7892\u001b[0m  1884.8599\n",
      "     11        \u001b[36m0.4836\u001b[0m       \u001b[32m0.7348\u001b[0m        0.7915  2832.6945\n",
      "     12        \u001b[36m0.4400\u001b[0m       \u001b[32m0.7368\u001b[0m        0.7914  2918.9338\n",
      "     13        \u001b[36m0.3984\u001b[0m       \u001b[32m0.7416\u001b[0m        0.7927  2502.4152\n",
      "     14        \u001b[36m0.3583\u001b[0m       0.7412        0.8081  2751.9188\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 16, the learning rate was 0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.5403\u001b[0m       \u001b[32m0.5760\u001b[0m        \u001b[35m1.1992\u001b[0m  2208.2255\n",
      "      2        \u001b[36m1.1425\u001b[0m       \u001b[32m0.6306\u001b[0m        \u001b[35m1.0490\u001b[0m  1908.7850\n",
      "      3        \u001b[36m0.9650\u001b[0m       \u001b[32m0.6673\u001b[0m        \u001b[35m0.9531\u001b[0m  2381.4564\n",
      "      4        \u001b[36m0.8508\u001b[0m       \u001b[32m0.6886\u001b[0m        \u001b[35m0.9051\u001b[0m  2243.9538\n",
      "      5        \u001b[36m0.7680\u001b[0m       0.6850        0.9369  3039.4427\n",
      "      6        \u001b[36m0.6954\u001b[0m       0.6813        0.9643  2009.9776\n",
      "      7        \u001b[36m0.6422\u001b[0m       0.6800        0.9796  1852.9855\n",
      "      8        \u001b[36m0.5855\u001b[0m       0.6866        0.9889  1923.2216\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 32, the learning rate was 0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.5969\u001b[0m       \u001b[32m0.5568\u001b[0m        \u001b[35m1.2330\u001b[0m  1852.2973\n",
      "      2        \u001b[36m1.1545\u001b[0m       \u001b[32m0.6319\u001b[0m        \u001b[35m1.0502\u001b[0m  1919.2373\n",
      "      3        \u001b[36m0.9796\u001b[0m       \u001b[32m0.6580\u001b[0m        \u001b[35m0.9890\u001b[0m  1955.3820\n",
      "      4        \u001b[36m0.8679\u001b[0m       \u001b[32m0.6725\u001b[0m        \u001b[35m0.9481\u001b[0m  2065.3813\n",
      "      5        \u001b[36m0.7888\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.9225\u001b[0m  2047.5048\n",
      "      6        \u001b[36m0.7265\u001b[0m       \u001b[32m0.6810\u001b[0m        0.9570  2038.7800\n",
      "      7        \u001b[36m0.6762\u001b[0m       0.6782        0.9940  2038.7441\n",
      "      8        \u001b[36m0.6333\u001b[0m       0.6657        1.0982  2026.2662\n",
      "      9        \u001b[36m0.5929\u001b[0m       0.6675        1.0986  2027.5202\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 64, the learning rate was 0.001\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m1.6344\u001b[0m       \u001b[32m0.5295\u001b[0m        \u001b[35m1.3157\u001b[0m  1943.4180\n",
      "      2        \u001b[36m1.2120\u001b[0m       \u001b[32m0.6068\u001b[0m        \u001b[35m1.1103\u001b[0m  1900.2877\n",
      "      3        \u001b[36m1.0708\u001b[0m       \u001b[32m0.6285\u001b[0m        \u001b[35m1.0560\u001b[0m  1920.2538\n",
      "      4        \u001b[36m0.9739\u001b[0m       \u001b[32m0.6414\u001b[0m        \u001b[35m1.0254\u001b[0m  2047.0268\n",
      "      5        \u001b[36m0.8986\u001b[0m       \u001b[32m0.6423\u001b[0m        1.0417  2594.3312\n",
      "      6        \u001b[36m0.8384\u001b[0m       0.6337        1.0671  2910.5896\n",
      "      7        \u001b[36m0.7984\u001b[0m       0.6396        1.0678  2163.7094\n",
      "      8        \u001b[36m0.7519\u001b[0m       0.6355        1.1093  1508.6315\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 16, the learning rate was 0.01\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m5.3360\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3033\u001b[0m  1572.3764\n",
      "      2        \u001b[36m2.3038\u001b[0m       0.1000        2.3034  1639.0350\n",
      "      3        2.3038       0.1000        2.3035  1821.6766\n",
      "      4        2.3039       0.1000        2.3035  1756.7726\n",
      "      5        2.3039       0.1000        2.3035  1845.7966\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "The channel was 32, the learning rate was 0.01\n",
      "  epoch    train_loss    valid_acc    valid_loss        dur\n",
      "-------  ------------  -----------  ------------  ---------\n",
      "      1        \u001b[36m4.6576\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m1.4754\u001b[0m  1711.5144\n",
      "      2        \u001b[36m1.4273\u001b[0m       \u001b[32m0.5073\u001b[0m        \u001b[35m1.3865\u001b[0m  1621.4952\n",
      "      3        \u001b[36m1.3586\u001b[0m       \u001b[32m0.5256\u001b[0m        \u001b[35m1.3293\u001b[0m  1622.3163\n"
     ]
    }
   ],
   "source": [
    "# implement hyperparameters, you can select and modify the hyperparameters by yourself here.\n",
    "learning_rate = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "channel = [16,32,64]\n",
    "# Select the better optimizer by the result shown in the previous problem, you can select and modify it by yourself here.\n",
    "better_optimizer = torch.optim.Adam  \n",
    "\n",
    "train_data_normalized = torch.Tensor(train.data/255)\n",
    "train_data_normalized = train_data_normalized.permute(0,3,1,2)\n",
    "\n",
    "for l in learning_rate:\n",
    "    for c in channel:\n",
    "      print(f'The channel was {c}, the learning rate was {l}')\n",
    "\n",
    "      cnn = CNN_MaxPool(channels = c)\n",
    "      \n",
    "      model = skorch.NeuralNetClassifier(cnn, criterion=torch.nn.CrossEntropyLoss,\n",
    "                                   device=\"cpu\",\n",
    "                                   optimizer=better_optimizer,\n",
    "                                   lr=l,\n",
    "                                   max_epochs=25,\n",
    "                                   batch_size=64,\n",
    "                                   callbacks=[skorch.callbacks.EarlyStopping(lower_is_better=True)])\n",
    "      # implement input normalization & type cast here \n",
    "      model.fit(train_data_normalized, np.asarray(train.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7Mu2ZZHoZU0"
   },
   "source": [
    "Write down the **validation accuracy** of the model under different hyperparameter settings.\n",
    "\n",
    "| #channel for each layer | validation accuracy |\n",
    "|-------------------------|---------------------|\n",
    "|        (16,16,16)       |        75.20        |\n",
    "|        (32,32,32)       |        75.13        |\n",
    "|        (64,64,64)       |        79.72        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UCaz8nWoWWS"
   },
   "source": [
    "For the best model you have, test it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bTtBk22OECDD",
    "outputId": "40229a37-f53c-4837-de75-8a63b3f66889"
   },
   "outputs": [],
   "source": [
    "# implement the same input normalization & type cast here\n",
    "test_data_normalized = torch.Tensor(test.data/255) \n",
    "test_data_normalized = test_data_normalized.permute(0,3,1,2)\n",
    "test.predictions = model.predict(test_data_normalized)\n",
    "sklearn.metrics.accuracy_score(test.targets, test.predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSbhC8f1or6_"
   },
   "source": [
    "How much **test accuracy** do you get? What can you conclude for the design of CNN structure and tuning of hyperparameters? (5 points)\n",
    "\n",
    "**Your Answer:* I get 70.5% test accuracy. The number of channels and learning rate are the most important hyperparameters. They should not be too large or too small. Adam optimizer is better than SGD optimizer because it can converge faster. The structure of CNN is also important. The max pooling layer can improve the performance of CNN. The kernel size and stride of max pooling layer should be appropriate.* **"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Adrien Hernandez Homework 1 - PyTorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f3b4a3b037d47cb8ba1196d7dbd3b98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "310efd92386a4757a767d5204b08a865": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_87cad6ba7ef84d03a7f8c0cb37ec01ec",
       "IPY_MODEL_b712d5d1ba464a378c00dbb2aec6dd8c"
      ],
      "layout": "IPY_MODEL_8346dadd8dcd437f9d0c73a8e86d4503"
     }
    },
    "3f3ef2c146bf4dd38424170b3090b055": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a89539615b4132a01ca7f5223ca281": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8346dadd8dcd437f9d0c73a8e86d4503": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87cad6ba7ef84d03a7f8c0cb37ec01ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f3ef2c146bf4dd38424170b3090b055",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f3b4a3b037d47cb8ba1196d7dbd3b98",
      "value": 1
     }
    },
    "adbb9a799ba44a91b927b44d0c27e6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b712d5d1ba464a378c00dbb2aec6dd8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44a89539615b4132a01ca7f5223ca281",
      "placeholder": "",
      "style": "IPY_MODEL_adbb9a799ba44a91b927b44d0c27e6d1",
      "value": "170500096it [00:04, 37859309.77it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
